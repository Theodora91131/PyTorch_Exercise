{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz0_QVkxCrX3"
   },
   "source": [
    "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeZnPAiwDRWG"
   },
   "source": [
    "Author: Heng-Jui Chang\n",
    "\n",
    "Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
    "Videos (Mandarin): https://cool.ntu.edu.tw/courses/4793/modules/items/172854  \n",
    "https://cool.ntu.edu.tw/courses/4793/modules/items/172853  \n",
    "Video (English): https://cool.ntu.edu.tw/courses/4793/modules/items/176529\n",
    "\n",
    "\n",
    "Objectives:\n",
    "* Solve a regression problem with deep neural networks (DNN).\n",
    "* Understand basic DNN training tips.\n",
    "* Get familiar with PyTorch.\n",
    "\n",
    "If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx3x1nDkG-Uy"
   },
   "source": [
    "# **Download Data**\n",
    "\n",
    "\n",
    "If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMj55YDKG6ch",
    "outputId": "fc40ecc9-4756-48b1-d5c6-c169a8b453b2"
   },
   "outputs": [],
   "source": [
    "tr_path = 'covid.train.csv'  # path to training data\n",
    "tt_path = 'covid.test.csv'   # path to testing data\n",
    "\n",
    "#!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
    "#!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data by using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AL</th>\n",
       "      <th>AK</th>\n",
       "      <th>AZ</th>\n",
       "      <th>AR</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>FL</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>restaurant.2</th>\n",
       "      <th>spent_time.2</th>\n",
       "      <th>large_event.2</th>\n",
       "      <th>public_transit.2</th>\n",
       "      <th>anxious.2</th>\n",
       "      <th>depressed.2</th>\n",
       "      <th>felt_isolated.2</th>\n",
       "      <th>worried_become_ill.2</th>\n",
       "      <th>worried_finances.2</th>\n",
       "      <th>tested_positive.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.812411</td>\n",
       "      <td>43.430423</td>\n",
       "      <td>16.151527</td>\n",
       "      <td>1.602635</td>\n",
       "      <td>15.409449</td>\n",
       "      <td>12.088688</td>\n",
       "      <td>16.702086</td>\n",
       "      <td>53.991549</td>\n",
       "      <td>43.604229</td>\n",
       "      <td>20.704935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.682974</td>\n",
       "      <td>43.196313</td>\n",
       "      <td>16.123386</td>\n",
       "      <td>1.641863</td>\n",
       "      <td>15.230063</td>\n",
       "      <td>11.809047</td>\n",
       "      <td>16.506973</td>\n",
       "      <td>54.185521</td>\n",
       "      <td>42.665766</td>\n",
       "      <td>21.292911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.593983</td>\n",
       "      <td>43.362200</td>\n",
       "      <td>16.159971</td>\n",
       "      <td>1.677523</td>\n",
       "      <td>15.717207</td>\n",
       "      <td>12.355918</td>\n",
       "      <td>16.273294</td>\n",
       "      <td>53.637069</td>\n",
       "      <td>42.972417</td>\n",
       "      <td>21.166656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.576992</td>\n",
       "      <td>42.954574</td>\n",
       "      <td>15.544373</td>\n",
       "      <td>1.578030</td>\n",
       "      <td>15.295650</td>\n",
       "      <td>12.218123</td>\n",
       "      <td>16.045504</td>\n",
       "      <td>52.446223</td>\n",
       "      <td>42.907472</td>\n",
       "      <td>19.896607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.091433</td>\n",
       "      <td>43.290957</td>\n",
       "      <td>15.214655</td>\n",
       "      <td>1.641667</td>\n",
       "      <td>14.778802</td>\n",
       "      <td>12.417256</td>\n",
       "      <td>16.134238</td>\n",
       "      <td>52.560315</td>\n",
       "      <td>43.321985</td>\n",
       "      <td>20.178428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   AL   AK   AZ   AR   CA   CO   CT   FL   GA  ...  restaurant.2  \\\n",
       "0   0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     23.812411   \n",
       "1   1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     23.682974   \n",
       "2   2  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     23.593983   \n",
       "3   3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     22.576992   \n",
       "4   4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     22.091433   \n",
       "\n",
       "   spent_time.2  large_event.2  public_transit.2  anxious.2  depressed.2  \\\n",
       "0     43.430423      16.151527          1.602635  15.409449    12.088688   \n",
       "1     43.196313      16.123386          1.641863  15.230063    11.809047   \n",
       "2     43.362200      16.159971          1.677523  15.717207    12.355918   \n",
       "3     42.954574      15.544373          1.578030  15.295650    12.218123   \n",
       "4     43.290957      15.214655          1.641667  14.778802    12.417256   \n",
       "\n",
       "   felt_isolated.2  worried_become_ill.2  worried_finances.2  \\\n",
       "0        16.702086             53.991549           43.604229   \n",
       "1        16.506973             54.185521           42.665766   \n",
       "2        16.273294             53.637069           42.972417   \n",
       "3        16.045504             52.446223           42.907472   \n",
       "4        16.134238             52.560315           43.321985   \n",
       "\n",
       "   tested_positive.2  \n",
       "0          20.704935  \n",
       "1          21.292911  \n",
       "2          21.166656  \n",
       "3          19.896607  \n",
       "4          20.178428  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_path = pd.read_csv(tr_path)\n",
    "tr_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AL</th>\n",
       "      <th>AK</th>\n",
       "      <th>AZ</th>\n",
       "      <th>AR</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>FL</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>shop.2</th>\n",
       "      <th>restaurant.2</th>\n",
       "      <th>spent_time.2</th>\n",
       "      <th>large_event.2</th>\n",
       "      <th>public_transit.2</th>\n",
       "      <th>anxious.2</th>\n",
       "      <th>depressed.2</th>\n",
       "      <th>felt_isolated.2</th>\n",
       "      <th>worried_become_ill.2</th>\n",
       "      <th>worried_finances.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.071090</td>\n",
       "      <td>8.624001</td>\n",
       "      <td>29.374792</td>\n",
       "      <td>5.391413</td>\n",
       "      <td>2.754804</td>\n",
       "      <td>19.695098</td>\n",
       "      <td>13.685645</td>\n",
       "      <td>24.747837</td>\n",
       "      <td>66.194950</td>\n",
       "      <td>44.873473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.742461</td>\n",
       "      <td>21.720187</td>\n",
       "      <td>41.375784</td>\n",
       "      <td>9.450179</td>\n",
       "      <td>3.150088</td>\n",
       "      <td>22.075715</td>\n",
       "      <td>17.302077</td>\n",
       "      <td>23.559622</td>\n",
       "      <td>57.015009</td>\n",
       "      <td>38.372829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.109045</td>\n",
       "      <td>20.123959</td>\n",
       "      <td>40.072556</td>\n",
       "      <td>8.781522</td>\n",
       "      <td>2.888209</td>\n",
       "      <td>23.920870</td>\n",
       "      <td>18.342506</td>\n",
       "      <td>24.993341</td>\n",
       "      <td>55.291498</td>\n",
       "      <td>38.907257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.442267</td>\n",
       "      <td>16.083529</td>\n",
       "      <td>36.977612</td>\n",
       "      <td>5.199286</td>\n",
       "      <td>2.575347</td>\n",
       "      <td>21.073800</td>\n",
       "      <td>12.087171</td>\n",
       "      <td>18.608723</td>\n",
       "      <td>67.036197</td>\n",
       "      <td>43.142779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.588783</td>\n",
       "      <td>19.503010</td>\n",
       "      <td>42.631236</td>\n",
       "      <td>11.549771</td>\n",
       "      <td>8.530551</td>\n",
       "      <td>15.896575</td>\n",
       "      <td>11.781634</td>\n",
       "      <td>15.065228</td>\n",
       "      <td>61.196518</td>\n",
       "      <td>43.574676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   AL   AK   AZ   AR   CA   CO   CT   FL   GA  ...     shop.2  \\\n",
       "0   0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  52.071090   \n",
       "1   1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  58.742461   \n",
       "2   2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  59.109045   \n",
       "3   3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  55.442267   \n",
       "4   4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  60.588783   \n",
       "\n",
       "   restaurant.2  spent_time.2  large_event.2  public_transit.2  anxious.2  \\\n",
       "0      8.624001     29.374792       5.391413          2.754804  19.695098   \n",
       "1     21.720187     41.375784       9.450179          3.150088  22.075715   \n",
       "2     20.123959     40.072556       8.781522          2.888209  23.920870   \n",
       "3     16.083529     36.977612       5.199286          2.575347  21.073800   \n",
       "4     19.503010     42.631236      11.549771          8.530551  15.896575   \n",
       "\n",
       "   depressed.2  felt_isolated.2  worried_become_ill.2  worried_finances.2  \n",
       "0    13.685645        24.747837             66.194950           44.873473  \n",
       "1    17.302077        23.559622             57.015009           38.372829  \n",
       "2    18.342506        24.993341             55.291498           38.907257  \n",
       "3    12.087171        18.608723             67.036197           43.142779  \n",
       "4    11.781634        15.065228             61.196518           43.574676  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_path = pd.read_csv(tt_path)\n",
    "tt_path.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_4-77xHk44"
   },
   "source": [
    "# **Import Some Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k-onQd4JNA5H"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 42069  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtE3b6JEH7rw"
   },
   "source": [
    "# **Some Utilities**\n",
    "\n",
    "You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "FWMT3uf1NGQp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot prediction of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39U_XFX6KOoj"
   },
   "source": [
    "# **Preprocess**\n",
    "\n",
    "We have three kinds of datasets:\n",
    "* `train`: for training\n",
    "* `dev`: for validation\n",
    "* `test`: for testing (w/o target value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ-MdwpLL7Dt"
   },
   "source": [
    "## **Dataset**\n",
    "\n",
    "The `COVID19Dataset` below does:\n",
    "* read `.csv` files\n",
    "* extract features\n",
    "* split `covid.train.csv` into train/dev sets\n",
    "* normalize features\n",
    "\n",
    "Finishing `TODO` below might make you pass medium baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "0zlpIp9ANJRU"
   },
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 mode='train',\n",
    "                 target_only=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "        \n",
    "        if not target_only:\n",
    "            feats = list(range(93))\n",
    "        else:\n",
    "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
    "            pass\n",
    "\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            # Training data (train/dev sets)\n",
    "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "            \n",
    "            # Splitting training data into train & dev sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "            \n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        # Normalize features (you may remove this part to see what will happen)\n",
    "        self.data[:, 40:] = \\\n",
    "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
    "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlhTlkE7MDo3"
   },
   "source": [
    "## **DataLoader**\n",
    "\n",
    "A `DataLoader` loads data from a given `Dataset` into batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "hlhLk5t6MBX3"
   },
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGuycwR0MeQB"
   },
   "source": [
    "# **Deep Neural Network**\n",
    "\n",
    "`NeuralNet` is an `nn.Module` designed for regression.\n",
    "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
    "This module also included a function `cal_loss` for calculating loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "49-uXYovOAI0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Define your neural network here\n",
    "        # TODO: How to modify this model to achieve better performance?\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128 Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Define your neural network here\n",
    "        # TODO: How to modify this model to achieve better performance?\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Define your neural network here\n",
    "        # TODO: How to modify this model to achieve better performance?\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvFWVjZ5Nvga"
   },
   "source": [
    "# **Train/Dev/Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAM8QecJOyqn"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "lOqcmYzMO7jB"
   },
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    ''' DNN training '''\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
    "                .format(epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hSd4Bn3O2PL"
   },
   "source": [
    "## **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "yrxrD3YsN3U2"
   },
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0pdrhQAO41L"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "aSBMRFlYN5tB"
   },
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    for x in tt_set:                            # iterate through the dataloader\n",
    "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvckkF5dvf0j"
   },
   "source": [
    "# **Setup Hyper-parameters**\n",
    "\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "NPXpdumwPjE7"
   },
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 3000,                # maximum number of epochs\n",
    "    'batch_size': 270,               # mini-batch size for dataloader\n",
    "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 0.001,                 # learning rate of SGD\n",
    "        'momentum': 0.9              # momentum for SGD\n",
    "    },\n",
    "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change optim Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 3000,                # maximum number of epochs\n",
    "    'batch_size': 270,               # mini-batch size for dataloader\n",
    "    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 0.001                 # learning rate of SGD\n",
    "                     # momentum for SGD\n",
    "    },\n",
    "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j1eOV3TOH-j"
   },
   "source": [
    "# **Load data and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNrYBMmePLKm",
    "outputId": "fcd4f175-4f7e-4306-f33c-5f8285f11dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
      "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
      "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
    "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
    "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "FHylSirLP9oh"
   },
   "outputs": [],
   "source": [
    "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sX2B_zgSOPTJ"
   },
   "source": [
    "# **Start Training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrEbUxazQAAZ",
    "outputId": "f4f3bd74-2d97-4275-b69f-6609976b91f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 78.8524)\n",
      "Saving model (epoch =    2, loss = 37.6170)\n",
      "Saving model (epoch =    3, loss = 26.1203)\n",
      "Saving model (epoch =    4, loss = 16.1862)\n",
      "Saving model (epoch =    5, loss = 9.7153)\n",
      "Saving model (epoch =    6, loss = 6.3701)\n",
      "Saving model (epoch =    7, loss = 5.1802)\n",
      "Saving model (epoch =    8, loss = 4.4255)\n",
      "Saving model (epoch =    9, loss = 3.8009)\n",
      "Saving model (epoch =   10, loss = 3.3691)\n",
      "Saving model (epoch =   11, loss = 3.0943)\n",
      "Saving model (epoch =   12, loss = 2.8176)\n",
      "Saving model (epoch =   13, loss = 2.6274)\n",
      "Saving model (epoch =   14, loss = 2.4542)\n",
      "Saving model (epoch =   15, loss = 2.3012)\n",
      "Saving model (epoch =   16, loss = 2.1766)\n",
      "Saving model (epoch =   17, loss = 2.0641)\n",
      "Saving model (epoch =   18, loss = 1.9399)\n",
      "Saving model (epoch =   19, loss = 1.8978)\n",
      "Saving model (epoch =   20, loss = 1.7950)\n",
      "Saving model (epoch =   21, loss = 1.7164)\n",
      "Saving model (epoch =   22, loss = 1.6455)\n",
      "Saving model (epoch =   23, loss = 1.5912)\n",
      "Saving model (epoch =   24, loss = 1.5599)\n",
      "Saving model (epoch =   25, loss = 1.5197)\n",
      "Saving model (epoch =   26, loss = 1.4698)\n",
      "Saving model (epoch =   27, loss = 1.4189)\n",
      "Saving model (epoch =   28, loss = 1.3992)\n",
      "Saving model (epoch =   29, loss = 1.3696)\n",
      "Saving model (epoch =   30, loss = 1.3442)\n",
      "Saving model (epoch =   31, loss = 1.3231)\n",
      "Saving model (epoch =   32, loss = 1.2834)\n",
      "Saving model (epoch =   33, loss = 1.2804)\n",
      "Saving model (epoch =   34, loss = 1.2471)\n",
      "Saving model (epoch =   36, loss = 1.2414)\n",
      "Saving model (epoch =   37, loss = 1.2138)\n",
      "Saving model (epoch =   38, loss = 1.2083)\n",
      "Saving model (epoch =   41, loss = 1.1591)\n",
      "Saving model (epoch =   42, loss = 1.1484)\n",
      "Saving model (epoch =   44, loss = 1.1209)\n",
      "Saving model (epoch =   47, loss = 1.1122)\n",
      "Saving model (epoch =   48, loss = 1.0937)\n",
      "Saving model (epoch =   50, loss = 1.0842)\n",
      "Saving model (epoch =   53, loss = 1.0655)\n",
      "Saving model (epoch =   54, loss = 1.0613)\n",
      "Saving model (epoch =   57, loss = 1.0524)\n",
      "Saving model (epoch =   58, loss = 1.0394)\n",
      "Saving model (epoch =   60, loss = 1.0267)\n",
      "Saving model (epoch =   63, loss = 1.0248)\n",
      "Saving model (epoch =   66, loss = 1.0099)\n",
      "Saving model (epoch =   70, loss = 0.9829)\n",
      "Saving model (epoch =   72, loss = 0.9817)\n",
      "Saving model (epoch =   73, loss = 0.9743)\n",
      "Saving model (epoch =   75, loss = 0.9671)\n",
      "Saving model (epoch =   78, loss = 0.9643)\n",
      "Saving model (epoch =   79, loss = 0.9597)\n",
      "Saving model (epoch =   85, loss = 0.9550)\n",
      "Saving model (epoch =   86, loss = 0.9535)\n",
      "Saving model (epoch =   90, loss = 0.9466)\n",
      "Saving model (epoch =   92, loss = 0.9432)\n",
      "Saving model (epoch =   93, loss = 0.9231)\n",
      "Saving model (epoch =   95, loss = 0.9127)\n",
      "Saving model (epoch =  104, loss = 0.9117)\n",
      "Saving model (epoch =  107, loss = 0.8996)\n",
      "Saving model (epoch =  110, loss = 0.8937)\n",
      "Saving model (epoch =  116, loss = 0.8885)\n",
      "Saving model (epoch =  124, loss = 0.8872)\n",
      "Saving model (epoch =  128, loss = 0.8724)\n",
      "Saving model (epoch =  134, loss = 0.8722)\n",
      "Saving model (epoch =  139, loss = 0.8675)\n",
      "Saving model (epoch =  146, loss = 0.8654)\n",
      "Saving model (epoch =  156, loss = 0.8640)\n",
      "Saving model (epoch =  159, loss = 0.8525)\n",
      "Saving model (epoch =  167, loss = 0.8496)\n",
      "Saving model (epoch =  173, loss = 0.8490)\n",
      "Saving model (epoch =  176, loss = 0.8458)\n",
      "Saving model (epoch =  178, loss = 0.8405)\n",
      "Saving model (epoch =  182, loss = 0.8371)\n",
      "Saving model (epoch =  199, loss = 0.8298)\n",
      "Saving model (epoch =  212, loss = 0.8274)\n",
      "Saving model (epoch =  235, loss = 0.8249)\n",
      "Saving model (epoch =  238, loss = 0.8232)\n",
      "Saving model (epoch =  251, loss = 0.8208)\n",
      "Saving model (epoch =  253, loss = 0.8202)\n",
      "Saving model (epoch =  258, loss = 0.8175)\n",
      "Saving model (epoch =  284, loss = 0.8139)\n",
      "Saving model (epoch =  308, loss = 0.8136)\n",
      "Saving model (epoch =  312, loss = 0.8076)\n",
      "Saving model (epoch =  324, loss = 0.8042)\n",
      "Saving model (epoch =  400, loss = 0.8039)\n",
      "Saving model (epoch =  404, loss = 0.8007)\n",
      "Saving model (epoch =  466, loss = 0.7999)\n",
      "Saving model (epoch =  472, loss = 0.7998)\n",
      "Saving model (epoch =  525, loss = 0.7990)\n",
      "Saving model (epoch =  561, loss = 0.7945)\n",
      "Saving model (epoch =  584, loss = 0.7902)\n",
      "Saving model (epoch =  667, loss = 0.7900)\n",
      "Saving model (epoch =  717, loss = 0.7827)\n",
      "Saving model (epoch =  776, loss = 0.7816)\n",
      "Saving model (epoch =  835, loss = 0.7797)\n",
      "Saving model (epoch =  866, loss = 0.7771)\n",
      "Saving model (epoch =  933, loss = 0.7749)\n",
      "Saving model (epoch =  965, loss = 0.7711)\n",
      "Saving model (epoch = 1027, loss = 0.7685)\n",
      "Saving model (epoch = 1119, loss = 0.7672)\n",
      "Saving model (epoch = 1140, loss = 0.7656)\n",
      "Saving model (epoch = 1196, loss = 0.7618)\n",
      "Saving model (epoch = 1243, loss = 0.7592)\n",
      "Finished training after 1444 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 38.2027)\n",
      "Saving model (epoch =    3, loss = 20.5664)\n",
      "Saving model (epoch =    4, loss = 9.0663)\n",
      "Saving model (epoch =    5, loss = 7.5639)\n",
      "Saving model (epoch =    6, loss = 6.2694)\n",
      "Saving model (epoch =    7, loss = 4.9485)\n",
      "Saving model (epoch =    8, loss = 3.8689)\n",
      "Saving model (epoch =    9, loss = 3.4882)\n",
      "Saving model (epoch =   10, loss = 3.2672)\n",
      "Saving model (epoch =   11, loss = 2.8618)\n",
      "Saving model (epoch =   12, loss = 2.7460)\n",
      "Saving model (epoch =   13, loss = 2.4874)\n",
      "Saving model (epoch =   14, loss = 2.3687)\n",
      "Saving model (epoch =   15, loss = 2.2131)\n",
      "Saving model (epoch =   16, loss = 2.1563)\n",
      "Saving model (epoch =   17, loss = 2.0396)\n",
      "Saving model (epoch =   18, loss = 1.9815)\n",
      "Saving model (epoch =   19, loss = 1.8692)\n",
      "Saving model (epoch =   20, loss = 1.8018)\n",
      "Saving model (epoch =   21, loss = 1.7445)\n",
      "Saving model (epoch =   22, loss = 1.6790)\n",
      "Saving model (epoch =   23, loss = 1.6319)\n",
      "Saving model (epoch =   24, loss = 1.5861)\n",
      "Saving model (epoch =   25, loss = 1.5373)\n",
      "Saving model (epoch =   26, loss = 1.5228)\n",
      "Saving model (epoch =   27, loss = 1.4750)\n",
      "Saving model (epoch =   28, loss = 1.4301)\n",
      "Saving model (epoch =   30, loss = 1.3910)\n",
      "Saving model (epoch =   31, loss = 1.3477)\n",
      "Saving model (epoch =   33, loss = 1.3136)\n",
      "Saving model (epoch =   34, loss = 1.2813)\n",
      "Saving model (epoch =   36, loss = 1.2478)\n",
      "Saving model (epoch =   38, loss = 1.2138)\n",
      "Saving model (epoch =   40, loss = 1.1723)\n",
      "Saving model (epoch =   42, loss = 1.1624)\n",
      "Saving model (epoch =   43, loss = 1.1603)\n",
      "Saving model (epoch =   44, loss = 1.1394)\n",
      "Saving model (epoch =   45, loss = 1.1221)\n",
      "Saving model (epoch =   47, loss = 1.0984)\n",
      "Saving model (epoch =   48, loss = 1.0821)\n",
      "Saving model (epoch =   50, loss = 1.0685)\n",
      "Saving model (epoch =   52, loss = 1.0634)\n",
      "Saving model (epoch =   53, loss = 1.0477)\n",
      "Saving model (epoch =   55, loss = 1.0365)\n",
      "Saving model (epoch =   56, loss = 1.0251)\n",
      "Saving model (epoch =   58, loss = 1.0016)\n",
      "Saving model (epoch =   61, loss = 0.9946)\n",
      "Saving model (epoch =   65, loss = 0.9780)\n",
      "Saving model (epoch =   66, loss = 0.9747)\n",
      "Saving model (epoch =   69, loss = 0.9590)\n",
      "Saving model (epoch =   71, loss = 0.9499)\n",
      "Saving model (epoch =   77, loss = 0.9373)\n",
      "Saving model (epoch =   80, loss = 0.9246)\n",
      "Saving model (epoch =   82, loss = 0.9205)\n",
      "Saving model (epoch =   84, loss = 0.9197)\n",
      "Saving model (epoch =   85, loss = 0.9007)\n",
      "Saving model (epoch =   88, loss = 0.8936)\n",
      "Saving model (epoch =   93, loss = 0.8904)\n",
      "Saving model (epoch =   95, loss = 0.8874)\n",
      "Saving model (epoch =   99, loss = 0.8788)\n",
      "Saving model (epoch =  103, loss = 0.8769)\n",
      "Saving model (epoch =  105, loss = 0.8767)\n",
      "Saving model (epoch =  108, loss = 0.8719)\n",
      "Saving model (epoch =  110, loss = 0.8693)\n",
      "Saving model (epoch =  112, loss = 0.8580)\n",
      "Saving model (epoch =  113, loss = 0.8570)\n",
      "Saving model (epoch =  119, loss = 0.8473)\n",
      "Saving model (epoch =  122, loss = 0.8452)\n",
      "Saving model (epoch =  125, loss = 0.8302)\n",
      "Saving model (epoch =  135, loss = 0.8227)\n",
      "Saving model (epoch =  147, loss = 0.8225)\n",
      "Saving model (epoch =  152, loss = 0.8196)\n",
      "Saving model (epoch =  158, loss = 0.8170)\n",
      "Saving model (epoch =  160, loss = 0.8143)\n",
      "Saving model (epoch =  162, loss = 0.8137)\n",
      "Saving model (epoch =  170, loss = 0.8088)\n",
      "Saving model (epoch =  185, loss = 0.8079)\n",
      "Saving model (epoch =  187, loss = 0.8064)\n",
      "Saving model (epoch =  192, loss = 0.8050)\n",
      "Saving model (epoch =  195, loss = 0.7960)\n",
      "Saving model (epoch =  209, loss = 0.7942)\n",
      "Saving model (epoch =  227, loss = 0.7923)\n",
      "Saving model (epoch =  237, loss = 0.7879)\n",
      "Saving model (epoch =  256, loss = 0.7871)\n",
      "Saving model (epoch =  264, loss = 0.7853)\n",
      "Saving model (epoch =  289, loss = 0.7788)\n",
      "Saving model (epoch =  298, loss = 0.7758)\n",
      "Saving model (epoch =  301, loss = 0.7745)\n",
      "Saving model (epoch =  314, loss = 0.7721)\n",
      "Saving model (epoch =  328, loss = 0.7716)\n",
      "Saving model (epoch =  336, loss = 0.7705)\n",
      "Saving model (epoch =  350, loss = 0.7677)\n",
      "Saving model (epoch =  371, loss = 0.7652)\n",
      "Saving model (epoch =  389, loss = 0.7648)\n",
      "Saving model (epoch =  390, loss = 0.7641)\n",
      "Saving model (epoch =  515, loss = 0.7606)\n",
      "Saving model (epoch =  541, loss = 0.7590)\n",
      "Saving model (epoch =  580, loss = 0.7546)\n",
      "Saving model (epoch =  598, loss = 0.7539)\n",
      "Finished training after 799 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 38.5879)\n",
      "Saving model (epoch =    2, loss = 35.4151)\n",
      "Saving model (epoch =    3, loss = 11.4263)\n",
      "Saving model (epoch =    5, loss = 7.5308)\n",
      "Saving model (epoch =    6, loss = 5.2419)\n",
      "Saving model (epoch =    7, loss = 4.3194)\n",
      "Saving model (epoch =    8, loss = 3.8057)\n",
      "Saving model (epoch =    9, loss = 3.3251)\n",
      "Saving model (epoch =   10, loss = 3.0578)\n",
      "Saving model (epoch =   11, loss = 2.7954)\n",
      "Saving model (epoch =   12, loss = 2.5703)\n",
      "Saving model (epoch =   13, loss = 2.4203)\n",
      "Saving model (epoch =   14, loss = 2.2635)\n",
      "Saving model (epoch =   15, loss = 2.1377)\n",
      "Saving model (epoch =   16, loss = 2.0493)\n",
      "Saving model (epoch =   17, loss = 1.9679)\n",
      "Saving model (epoch =   18, loss = 1.8606)\n",
      "Saving model (epoch =   19, loss = 1.7880)\n",
      "Saving model (epoch =   20, loss = 1.7318)\n",
      "Saving model (epoch =   21, loss = 1.6603)\n",
      "Saving model (epoch =   22, loss = 1.6219)\n",
      "Saving model (epoch =   23, loss = 1.5780)\n",
      "Saving model (epoch =   24, loss = 1.5210)\n",
      "Saving model (epoch =   25, loss = 1.4943)\n",
      "Saving model (epoch =   26, loss = 1.4503)\n",
      "Saving model (epoch =   27, loss = 1.4091)\n",
      "Saving model (epoch =   28, loss = 1.3880)\n",
      "Saving model (epoch =   30, loss = 1.3465)\n",
      "Saving model (epoch =   31, loss = 1.3363)\n",
      "Saving model (epoch =   32, loss = 1.3173)\n",
      "Saving model (epoch =   33, loss = 1.2723)\n",
      "Saving model (epoch =   35, loss = 1.2468)\n",
      "Saving model (epoch =   36, loss = 1.2467)\n",
      "Saving model (epoch =   38, loss = 1.2202)\n",
      "Saving model (epoch =   39, loss = 1.1861)\n",
      "Saving model (epoch =   40, loss = 1.1838)\n",
      "Saving model (epoch =   41, loss = 1.1717)\n",
      "Saving model (epoch =   42, loss = 1.1707)\n",
      "Saving model (epoch =   43, loss = 1.1457)\n",
      "Saving model (epoch =   45, loss = 1.1271)\n",
      "Saving model (epoch =   47, loss = 1.0931)\n",
      "Saving model (epoch =   50, loss = 1.0728)\n",
      "Saving model (epoch =   54, loss = 1.0693)\n",
      "Saving model (epoch =   55, loss = 1.0432)\n",
      "Saving model (epoch =   57, loss = 1.0324)\n",
      "Saving model (epoch =   61, loss = 1.0089)\n",
      "Saving model (epoch =   62, loss = 1.0064)\n",
      "Saving model (epoch =   65, loss = 0.9904)\n",
      "Saving model (epoch =   67, loss = 0.9864)\n",
      "Saving model (epoch =   68, loss = 0.9857)\n",
      "Saving model (epoch =   71, loss = 0.9737)\n",
      "Saving model (epoch =   72, loss = 0.9704)\n",
      "Saving model (epoch =   74, loss = 0.9663)\n",
      "Saving model (epoch =   81, loss = 0.9512)\n",
      "Saving model (epoch =   83, loss = 0.9248)\n",
      "Saving model (epoch =   87, loss = 0.9232)\n",
      "Saving model (epoch =   92, loss = 0.9145)\n",
      "Saving model (epoch =   94, loss = 0.9053)\n",
      "Saving model (epoch =   95, loss = 0.9018)\n",
      "Saving model (epoch =   99, loss = 0.8995)\n",
      "Saving model (epoch =  101, loss = 0.8897)\n",
      "Saving model (epoch =  109, loss = 0.8816)\n",
      "Saving model (epoch =  116, loss = 0.8745)\n",
      "Saving model (epoch =  118, loss = 0.8628)\n",
      "Saving model (epoch =  136, loss = 0.8552)\n",
      "Saving model (epoch =  137, loss = 0.8540)\n",
      "Saving model (epoch =  143, loss = 0.8507)\n",
      "Saving model (epoch =  145, loss = 0.8350)\n",
      "Saving model (epoch =  153, loss = 0.8318)\n",
      "Saving model (epoch =  160, loss = 0.8305)\n",
      "Saving model (epoch =  173, loss = 0.8270)\n",
      "Saving model (epoch =  177, loss = 0.8198)\n",
      "Saving model (epoch =  180, loss = 0.8158)\n",
      "Saving model (epoch =  191, loss = 0.8155)\n",
      "Saving model (epoch =  204, loss = 0.8128)\n",
      "Saving model (epoch =  219, loss = 0.8124)\n",
      "Saving model (epoch =  220, loss = 0.8091)\n",
      "Saving model (epoch =  225, loss = 0.7966)\n",
      "Saving model (epoch =  275, loss = 0.7933)\n",
      "Saving model (epoch =  277, loss = 0.7921)\n",
      "Saving model (epoch =  281, loss = 0.7894)\n",
      "Saving model (epoch =  284, loss = 0.7876)\n",
      "Saving model (epoch =  296, loss = 0.7824)\n",
      "Saving model (epoch =  312, loss = 0.7806)\n",
      "Saving model (epoch =  334, loss = 0.7779)\n",
      "Saving model (epoch =  342, loss = 0.7763)\n",
      "Saving model (epoch =  350, loss = 0.7683)\n",
      "Saving model (epoch =  396, loss = 0.7663)\n",
      "Saving model (epoch =  398, loss = 0.7630)\n",
      "Saving model (epoch =  419, loss = 0.7587)\n",
      "Saving model (epoch =  465, loss = 0.7555)\n",
      "Saving model (epoch =  517, loss = 0.7547)\n",
      "Saving model (epoch =  519, loss = 0.7507)\n",
      "Saving model (epoch =  524, loss = 0.7490)\n",
      "Saving model (epoch =  595, loss = 0.7436)\n",
      "Saving model (epoch =  638, loss = 0.7376)\n",
      "Saving model (epoch =  693, loss = 0.7344)\n",
      "Saving model (epoch =  739, loss = 0.7307)\n",
      "Saving model (epoch =  793, loss = 0.7292)\n",
      "Saving model (epoch =  847, loss = 0.7290)\n",
      "Saving model (epoch =  876, loss = 0.7250)\n",
      "Saving model (epoch =  935, loss = 0.7237)\n",
      "Saving model (epoch =  973, loss = 0.7237)\n",
      "Saving model (epoch =  985, loss = 0.7150)\n",
      "Finished training after 1186 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 282.5740)\n",
      "Saving model (epoch =    2, loss = 240.3181)\n",
      "Saving model (epoch =    3, loss = 190.7273)\n",
      "Saving model (epoch =    4, loss = 137.1409)\n",
      "Saving model (epoch =    5, loss = 88.0978)\n",
      "Saving model (epoch =    6, loss = 52.9460)\n",
      "Saving model (epoch =    7, loss = 36.4482)\n",
      "Saving model (epoch =    8, loss = 31.7930)\n",
      "Saving model (epoch =    9, loss = 29.3450)\n",
      "Saving model (epoch =   10, loss = 26.5065)\n",
      "Saving model (epoch =   11, loss = 24.4340)\n",
      "Saving model (epoch =   12, loss = 22.8836)\n",
      "Saving model (epoch =   13, loss = 21.4833)\n",
      "Saving model (epoch =   14, loss = 20.1332)\n",
      "Saving model (epoch =   15, loss = 18.8828)\n",
      "Saving model (epoch =   16, loss = 17.6727)\n",
      "Saving model (epoch =   17, loss = 16.5272)\n",
      "Saving model (epoch =   18, loss = 15.3833)\n",
      "Saving model (epoch =   19, loss = 14.3221)\n",
      "Saving model (epoch =   20, loss = 13.2873)\n",
      "Saving model (epoch =   21, loss = 12.3128)\n",
      "Saving model (epoch =   22, loss = 11.3656)\n",
      "Saving model (epoch =   23, loss = 10.5036)\n",
      "Saving model (epoch =   24, loss = 9.6777)\n",
      "Saving model (epoch =   25, loss = 8.8764)\n",
      "Saving model (epoch =   26, loss = 8.1513)\n",
      "Saving model (epoch =   27, loss = 7.4666)\n",
      "Saving model (epoch =   28, loss = 6.8483)\n",
      "Saving model (epoch =   29, loss = 6.2841)\n",
      "Saving model (epoch =   30, loss = 5.7549)\n",
      "Saving model (epoch =   31, loss = 5.2967)\n",
      "Saving model (epoch =   32, loss = 4.8817)\n",
      "Saving model (epoch =   33, loss = 4.5126)\n",
      "Saving model (epoch =   34, loss = 4.1846)\n",
      "Saving model (epoch =   35, loss = 3.9014)\n",
      "Saving model (epoch =   36, loss = 3.6419)\n",
      "Saving model (epoch =   37, loss = 3.4188)\n",
      "Saving model (epoch =   38, loss = 3.2309)\n",
      "Saving model (epoch =   39, loss = 3.0619)\n",
      "Saving model (epoch =   40, loss = 2.9148)\n",
      "Saving model (epoch =   41, loss = 2.7910)\n",
      "Saving model (epoch =   42, loss = 2.6767)\n",
      "Saving model (epoch =   43, loss = 2.5784)\n",
      "Saving model (epoch =   44, loss = 2.4903)\n",
      "Saving model (epoch =   45, loss = 2.4141)\n",
      "Saving model (epoch =   46, loss = 2.3395)\n",
      "Saving model (epoch =   47, loss = 2.2771)\n",
      "Saving model (epoch =   48, loss = 2.2112)\n",
      "Saving model (epoch =   49, loss = 2.1609)\n",
      "Saving model (epoch =   50, loss = 2.1005)\n",
      "Saving model (epoch =   51, loss = 2.0583)\n",
      "Saving model (epoch =   52, loss = 2.0172)\n",
      "Saving model (epoch =   53, loss = 1.9756)\n",
      "Saving model (epoch =   54, loss = 1.9357)\n",
      "Saving model (epoch =   55, loss = 1.9010)\n",
      "Saving model (epoch =   56, loss = 1.8571)\n",
      "Saving model (epoch =   57, loss = 1.8304)\n",
      "Saving model (epoch =   58, loss = 1.7989)\n",
      "Saving model (epoch =   59, loss = 1.7624)\n",
      "Saving model (epoch =   60, loss = 1.7330)\n",
      "Saving model (epoch =   61, loss = 1.7144)\n",
      "Saving model (epoch =   62, loss = 1.6840)\n",
      "Saving model (epoch =   63, loss = 1.6608)\n",
      "Saving model (epoch =   64, loss = 1.6417)\n",
      "Saving model (epoch =   65, loss = 1.6119)\n",
      "Saving model (epoch =   66, loss = 1.5968)\n",
      "Saving model (epoch =   67, loss = 1.5734)\n",
      "Saving model (epoch =   68, loss = 1.5523)\n",
      "Saving model (epoch =   69, loss = 1.5315)\n",
      "Saving model (epoch =   70, loss = 1.5205)\n",
      "Saving model (epoch =   71, loss = 1.5129)\n",
      "Saving model (epoch =   72, loss = 1.4739)\n",
      "Saving model (epoch =   73, loss = 1.4696)\n",
      "Saving model (epoch =   74, loss = 1.4533)\n",
      "Saving model (epoch =   75, loss = 1.4479)\n",
      "Saving model (epoch =   76, loss = 1.4226)\n",
      "Saving model (epoch =   77, loss = 1.4151)\n",
      "Saving model (epoch =   78, loss = 1.3920)\n",
      "Saving model (epoch =   79, loss = 1.3798)\n",
      "Saving model (epoch =   81, loss = 1.3671)\n",
      "Saving model (epoch =   82, loss = 1.3357)\n",
      "Saving model (epoch =   83, loss = 1.3319)\n",
      "Saving model (epoch =   84, loss = 1.3239)\n",
      "Saving model (epoch =   85, loss = 1.3098)\n",
      "Saving model (epoch =   86, loss = 1.3035)\n",
      "Saving model (epoch =   87, loss = 1.2866)\n",
      "Saving model (epoch =   88, loss = 1.2862)\n",
      "Saving model (epoch =   89, loss = 1.2680)\n",
      "Saving model (epoch =   90, loss = 1.2662)\n",
      "Saving model (epoch =   91, loss = 1.2574)\n",
      "Saving model (epoch =   92, loss = 1.2440)\n",
      "Saving model (epoch =   93, loss = 1.2256)\n",
      "Saving model (epoch =   94, loss = 1.2209)\n",
      "Saving model (epoch =   96, loss = 1.2041)\n",
      "Saving model (epoch =   97, loss = 1.1977)\n",
      "Saving model (epoch =   98, loss = 1.1924)\n",
      "Saving model (epoch =   99, loss = 1.1789)\n",
      "Saving model (epoch =  100, loss = 1.1764)\n",
      "Saving model (epoch =  101, loss = 1.1684)\n",
      "Saving model (epoch =  102, loss = 1.1658)\n",
      "Saving model (epoch =  103, loss = 1.1590)\n",
      "Saving model (epoch =  104, loss = 1.1446)\n",
      "Saving model (epoch =  105, loss = 1.1333)\n",
      "Saving model (epoch =  107, loss = 1.1287)\n",
      "Saving model (epoch =  108, loss = 1.1227)\n",
      "Saving model (epoch =  110, loss = 1.1202)\n",
      "Saving model (epoch =  111, loss = 1.0997)\n",
      "Saving model (epoch =  112, loss = 1.0873)\n",
      "Saving model (epoch =  114, loss = 1.0868)\n",
      "Saving model (epoch =  115, loss = 1.0693)\n",
      "Saving model (epoch =  118, loss = 1.0514)\n",
      "Saving model (epoch =  122, loss = 1.0479)\n",
      "Saving model (epoch =  123, loss = 1.0386)\n",
      "Saving model (epoch =  124, loss = 1.0261)\n",
      "Saving model (epoch =  129, loss = 1.0199)\n",
      "Saving model (epoch =  130, loss = 1.0053)\n",
      "Saving model (epoch =  133, loss = 0.9947)\n",
      "Saving model (epoch =  136, loss = 0.9817)\n",
      "Saving model (epoch =  138, loss = 0.9755)\n",
      "Saving model (epoch =  140, loss = 0.9665)\n",
      "Saving model (epoch =  141, loss = 0.9605)\n",
      "Saving model (epoch =  143, loss = 0.9520)\n",
      "Saving model (epoch =  145, loss = 0.9404)\n",
      "Saving model (epoch =  150, loss = 0.9345)\n",
      "Saving model (epoch =  154, loss = 0.9314)\n",
      "Saving model (epoch =  156, loss = 0.9205)\n",
      "Saving model (epoch =  158, loss = 0.9085)\n",
      "Saving model (epoch =  163, loss = 0.9016)\n",
      "Saving model (epoch =  164, loss = 0.8956)\n",
      "Saving model (epoch =  170, loss = 0.8913)\n",
      "Saving model (epoch =  172, loss = 0.8888)\n",
      "Saving model (epoch =  173, loss = 0.8747)\n",
      "Saving model (epoch =  184, loss = 0.8674)\n",
      "Saving model (epoch =  188, loss = 0.8532)\n",
      "Saving model (epoch =  194, loss = 0.8469)\n",
      "Saving model (epoch =  201, loss = 0.8419)\n",
      "Saving model (epoch =  203, loss = 0.8387)\n",
      "Saving model (epoch =  210, loss = 0.8291)\n",
      "Saving model (epoch =  216, loss = 0.8255)\n",
      "Saving model (epoch =  219, loss = 0.8192)\n",
      "Saving model (epoch =  225, loss = 0.8122)\n",
      "Saving model (epoch =  229, loss = 0.8120)\n",
      "Saving model (epoch =  232, loss = 0.8032)\n",
      "Saving model (epoch =  250, loss = 0.8025)\n",
      "Saving model (epoch =  251, loss = 0.7981)\n",
      "Saving model (epoch =  260, loss = 0.7949)\n",
      "Saving model (epoch =  261, loss = 0.7887)\n",
      "Saving model (epoch =  263, loss = 0.7866)\n",
      "Saving model (epoch =  275, loss = 0.7733)\n",
      "Saving model (epoch =  284, loss = 0.7663)\n",
      "Saving model (epoch =  316, loss = 0.7614)\n",
      "Saving model (epoch =  320, loss = 0.7571)\n",
      "Saving model (epoch =  366, loss = 0.7553)\n",
      "Saving model (epoch =  377, loss = 0.7522)\n",
      "Saving model (epoch =  394, loss = 0.7509)\n",
      "Saving model (epoch =  398, loss = 0.7406)\n",
      "Saving model (epoch =  461, loss = 0.7389)\n",
      "Saving model (epoch =  466, loss = 0.7357)\n",
      "Saving model (epoch =  490, loss = 0.7305)\n",
      "Saving model (epoch =  506, loss = 0.7295)\n",
      "Saving model (epoch =  520, loss = 0.7265)\n",
      "Saving model (epoch =  617, loss = 0.7256)\n",
      "Saving model (epoch =  666, loss = 0.7238)\n",
      "Saving model (epoch =  693, loss = 0.7199)\n",
      "Saving model (epoch =  721, loss = 0.7171)\n",
      "Saving model (epoch =  792, loss = 0.7115)\n",
      "Saving model (epoch =  831, loss = 0.7065)\n",
      "Finished training after 1032 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hsNO9nnXQBvP",
    "outputId": "1626def6-94c7-4a87-9447-d939f827c8eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(model_loss_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "3iZTVn5WQFpX",
    "outputId": "a2d5e118-559d-45c6-b644-6792af54663d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAFNCAYAAACE8D3EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABO2ElEQVR4nO2dd3hUZfbHPyc9EAIBQieAoKJiRBd7QQEFGwJiX7Hg2te2rvXHit11sa69oKhYEFGxi9LWLiJGEEQphl5DEkjPvL8/zh1mCCmTyGQmyfk8zzwz984t71zgy3nf08Q5h2EYhhEaMZEegGEYRkPCRNMwDKMWmGgahmHUAhNNwzCMWmCiaRiGUQtMNA3DMGqBiaYREiLSXUSciMRF4N7LRWRQfd+3vqn4jEXkIxE5rw7XyRCRrSISu+tHaZhoRhEicqaIfCsi20Rkvff5chGRSI+tOrx/oP6XT0QKg7bPqeW1XhSRu8I11j+LiJwvIuXeb8sTkXkiclI47uWcO945NyGEMe3wn4pzLts5l+KcKw/HuJo6JppRgoj8A3gE+A/QAWgPXAocDiRUcU5UWBLeP9AU51wKkA2cHLRvov+4SFipYeJr77e2Ap4HJolI64oHNaLfawRhohkFiEhL4A7gcufcZOdcvlN+dM6d45wr9o57UUSeFJEPRWQbcIyI7CUiM0Vki4gsEJGhQdedKSIXBW2fLyJfBG07EblURH4TkRwRedxv1YpIrIiME5GNIrIUOLEOv+toEVkpIjeKyFrghYpjCBpHLxG5GDgHuMGz5N4LOqyviGSJSK6IvCEiSZXcL9F7Dn2C9qV7lm+7Csf2EpFZ3vU2isgbtf19zjkfMB5IBnYTkbEiMllEXhGRPOB8EWkpIs+LyBoRWSUid/n/s6vpGVfy5/c3EVkoIvki8ouIHCAiLwMZwHveM7uhkml+JxGZKiKbReR3Eflb0DXHisgkEXnJu+4CEelX22fRlDDRjA4OBRKBd0M49mzgbqAF8C3wHvAp0A74OzBRRPasxb1PAg4E9gNOBwZ7+//mfbc/0A8YWYtrBtMBaA10Ay6u7kDn3DPAROB+z0o9Oejr04EhQA8gEzi/kvOLgSnAWRXOm+WcW1/h8DvR55YGdAH+G/pPUjxRugjYCvzm7T4FmIxaoROBCUAZ0At9lsd550AtnrGInAaMBUYBqcBQYJNz7lx2tO7vr+T014CVQCfvHveIyMCg74cCr3tjngo8FtoTaJqYaEYHbYGNzrky/w4R+cqzmgpF5KigY991zn3pWTl9gRTgPudciXNuOvA+O4pGTdznnNvinMsGZnjXBBWbh51zK5xzm4F76/jbfMBtzrli51xhHa8B8KhzbrU3lveCxlmRV9nx95/t7atIKSrknZxzRc65Lyo5pioOEZEtwFrvXsOdc7ned187597x/nxSgeOBa5xz2zzhfgg40zu2Ns/4IvQ/k++9Wcjvzrk/ahqoiHQFjgBu9H7nPOA54Nygw75wzn3orYG+jP4HalSBiWZ0sAloG7wG5pw7zDnXyvsu+M9pRdDnTsAK7x+onz+AzrW499qgzwWoCG+/doXr1oUNzrmiOp4bTFXjrMh0IFlEDhaRbqi4vl3JcTcAAnznTUkvrMVYvnHOtXLOtXXOHeKc+yzou+Bn1g2IB9Z4/wFuAZ5GZwVQu2fcFVhSizH66QRsds7lV7hP8N+Ris82ydZjq8YeTHTwNVCMTu3equHY4LJUq4GuIhITJJwZwGLv8zagWdDxHWoxpjXoP1Q/GbU4N5iKZbR2GJOIVBzTnyq75Zzzicgk1AJcB7xfQTD8x61Fp8eIyBHAZyIy2zn3+5+5PzuOfwX659o2eBYRRG2e8QqgZwj3rMhqoLWItAh6DhnAqmrOMarBLM0owDm3BbgdeEJERopIiojEiEhfoHk1p36LitANIhIvIkcDJ6PrUwDzgBEi0kxEegGjazGsScBVItJFRNKAm2pxbnX8BOwjIn09Z87YCt+vA3b7k/d4FTgDdSpVNjVHRE4TkS7eZg4qPLs0RMc5twZdN31ARFK9P9OeItLfO6Q2z/g54HoR+YsovTxLGqp5Zs65FcBXwL0ikiQimejfg4mVHW/UjIlmlOAt4F+HThvXo/8QngZuRP/SV3ZOCbqIfzywEXgCGOWcW+Qd8hBQ4l1rArX7h/Is8AkqcnNRB8ufxjm3GI0U+Ax1nlRcS3we2Nubzr5Tx3v4/zPpBHzk3+95l4/0Ng8EvhWRrajz42rn3DLvuAVSy/jSahiFhoz9gorzZKCj913Iz9g59ybqAHwVyAfeQR1soGuh/+c9s+srOf0soDtqdb6NrjFP+zM/qikjVoTYMAwjdMzSNAzDqAVhE01v/eQ7EfnJm+7c7u0f6wX5zvNeJ4RrDIZhGLuasE3PRUSA5s65rSISj65dXY0GKG91zo0Ly40NwzDCSNhCjpyq8VZvM9572QKqYRgNmrCuaXq5tfNQb/A0z6sJcKVoHvF4L9TCMAyjQVAv3nMRaYWGOvwd2ICGxzg0/7ejc26nbAzR4g0XAzRv3vwvvXv3Dvs4DcNoGixfDps2Afyw0TmXXptz6y3kSERuA7YFr2WKSHc0Y6NPlScC/fr1c3PmzAnzCA3DaNRkZVH65juMmjiY15cdzB2Xr+VfT3T8wTlXq6pO4fSep3sWJiKSDAwCFolIx6DDhgPzwzUGwzAMALKyKPn3Q5z52im8vuxg/n34u4zJv4FmWtavVoQz97wjMMGrHRgDTHLOvS8iL3vpgQ5YDlwSxjEYhmFQPOldTvv6Ot5bti8PDf6Yaw75EXLSaK3l8GpFOL3nWWidwIr7z63kcMMwjLBQWAgjXhzGx6v25YkT3ueyA72lvpYtSdA6trXCqhwZhtFo2bYNTjkFpq/qw3MDX2P0gb8GvszNpUSrUNUKS6M0DKNRkp8PJ5wAM2bAi3etYHSnjyAnB3w+fc/JYTNsqe11TTQNw2h05H45n8F7r+DL/5UzcfhkRp28Ba6/HtLSYOVKfb/+egqg1t0EbHpuGEajIueLBQwelsyPOZ1449Q3ObXT1zBuqorm2LE7HFsX77lZmoZhNBo2boQBp7Xmp5xuTDn9DU7dZ5FalWlpMKVCudKsLDpqq+xaYZamYRiNgvXrYdAgWLyhLe+e8SpD9lga+LJlS8jO3vGEKVMoq0O1frM0DcNo8KxZA0cfDb//Dh+c/SpD0n/Y8YDcXMio0IIpOxufiaZhGE2NlSuhf381JD/6CAZev/9273iwp5wRI3Y8MSODGIit7f1MNA3DaLAsXw5HHQXr1sGnn6p4kplZqaeczMwdTx4xgrg6iKataRqG0SBZsgQGDIC8PJg2DQ46KOjLzMydRbIimZms0aaDtcJE0zCMBsevv8LAgZoi+fnncMABdbuOxWkahtHo+eUXtTB9Ppg5E/bdt37vb2uahmE0GLKy1EsuEhnBBBNNwzAaCHPnwjHHQEICzJoFe+8dmXGYaBqGEfV8952uYaakwOzZsMcekRuLrWkahhHVfPklHH88pKfD9OnQrdufuFhWlqZTZmdDRoblnhuG0biYORMGD4aOHXVK/qcFc9w4DXTv0gVycuqUe26iaRhGVPLZZ1oPs1s3Fc8uXf7kBadMCRTviImBtDTLPTcMo3Hw0Udw0knQq5cWEe7YseZzaiQ7Wwt3BGG554ZhNHimToVhw9Q7PmMGtGu3iy6ckaGFO4Kw3HPDMBo0kyfDqadC376a6dOmzS68+IgROxXyqEvuuYmmYRhRwauvwplnag75tGmQ9vlkjWTffXd9nzz5z92gkkIedck9F+fcnxtIPdCvXz83Z86cSA/DMIwwMWECXHghHHkkvP8+pHw8GW64AVJT9ZWXp6/774eRI3fZfUXkB+dcv9qcY5amYRgR5bmxK7ngfMeADgv48PC7SVmaBY89pmLZqpV6ulu10u3HHov0cE00DcOIHI/fsoq/3d6Fwd0WMnXUWzTbul5jKZcuVZEMJjUVVq2KzECDsIwgwzAiwkMPwXX3dmZoj5+ZdPY7JMb5IDFNv4yJ0el4q1aBE/LyoHPniIw1GLM0DcOod+67D667Dk7tNoc3z5pCYlxQuGTLltCjh4rkli3q6d6yRbevvDJSQ96OiaZhGPXKHXfAzTfDWWfB66M+JGHr5h0PyM3VvhX336+W5po1+r6LnUB1xabnhmHUC87BmDFw990wahSMHw+xC4bpGiaohZmbq3GUo0driFAUiGRFzNI0DCPsOKcRRHffDRddBC+8ALGxhN4ELYoIm6UpIknAbCDRu89k59xtItIaeAPoDiwHTnfO5YRrHIZhRBbn4Jpr4NFH4fLL4b//VT/PdkJpghZFhHN6XgwMcM5tFZF44AsR+QgYAXzunLtPRG4CbgJuDOM4DMOIED4fXHEFPPUUXHstPPCAtqrYiQp1LhkxImqFNGzTc6ds9TbjvZcDTgEmePsnAMPCNQbDMCJHeTn87W8qmDfeWINgVqhzybhxuj8KCeuapojEisg8YD0wzTn3LdDeObcGwHvfVTVMDMOIEsrK4Pzz1dnzr3/BvfdWIZhQaZ1L0tJ0fxQSVtF0zpU75/oCXYCDRKRPqOeKyMUiMkdE5mzYsCFsYzQMY9dSWgrnnAOvvAJ33QW3316NYEKldS5p2VL3RyH1EnLknNsiIjOBIcA6EenonFsjIh1RK7Syc54BngEt2FEf4zQMoxpCWHcsKdFKRW+/Df/5jzrCayQjQ6fkaWmBfbm5uj8KCZulKSLpItLK+5wMDAIWAVOB87zDzgPeDdcYDMPYRYSw7lhUpDr69tvwyCMhCiZUWueSnBzdH4WEc3reEZghIlnA9+ia5vvAfcCxIvIbcKy3bRhGNFPDumNhIZxyCnzwATz5JFx1VS2u3cBiNcM2PXfOZQH7V7J/EzAwXPc1DONPUtk0PDt7585m3rrjtm1w8sna/Oz557UuZq1pQLGalhFkGEaAqqbhiYk79dchN5f89r04/nhtr/vSS3UUzAaG5Z4bhhEgeBoOgffiYhVQUAtzyRJyf1rOkNXP8/0WH6/et4Iz/vpnmpI3HMzSNAwjQFXhPyUlgXXHrCw2z8tm0JqX+CG3F2+e8AJnzB8TtcHouxoTTcMwAlTS5nZ7+E9mJowdy8Y9DmPg+tfIyu3GlDMmMbzfiqgORt/VmGgahhGghvCfdevg6GfPZtGW9kw98zVO2mOxnhfFwei7GhNNwzACVBP+s3q1dtJdtq0dH5z8NIN7LQmcF8XB6LsacwQZRlMilGpClYT/rFgBAwbA2rXw8TPZHDn9O8hJ27lwcBPALE3DaCrUsZrQ8uXafWL92nI+Pf05jpx9DzRvrh71BhCMvqsxS9MwmgpVhRNNmVKl4P3+u1qY+VvK+OzIOzkwZQu07BKwLpuQWPox0TSMpkJlWT1FRfDuu5VO1xctgoED1aCccfZz9E3cUivBbazY9NwwmgoVw4nWrYPZsyEhYafp+vz56vQpK9P0yL4l3zWo8m3hxETTMJoKFcOJ5s7V/fvvv0MRjp+e+JJjjtFds2ZBnz5UH7/ZxDDRNIymQsVwouJiOOoo6NBh+yE/FPTmmBfOJSlJBbN3b++LBla+LZyIc9Ff37dfv35uzpw5kR6GYUQvdWlMNnasCl9xMSxaxDerMxiy9HFaJZcwI6sNPXrsgntEOSLyg3OuX23OMUeQYTR0/KFEaWk7rk3W5NkeMQJuuQWWLOELjuD4JQ/TPnYj0w++nYz8a4Ca4zebIjY9N4yGTl0bk2VmQteuzORoBi9+lM6Jm5h1xpNk7NOiyeSR1wWzNA2joVNNgeCamLa0J6f8fhU92mzh81GT6JCSBL6EJukVDxWzNA2joVMXz3ZWFh+eM5GTp/2d3eP/YOYJ/6FDytbQzm3imGgaRkOntp7trCzeuWo6w14/g33arGV6l1Gkf/s+rFnTpL3ioWKiaRgNnVo2JnvzzkWc9r+/c0DHtXw++jXaDNgPUlPhu++aXB55XbA1TcNoSIQa9rN4caXHTZwIo94ayWFdVvDBOa+SmliscZqDB6vgjh1b7z+poWFxmobRUAgOLQouyTZ0KEydGtj/++/wzTdw6KGQkgLz5sGmTbzYdQwXzhpF/46Lea/jJaSU5+rx6ekqriUl2oe3EcRfhorFaRpGY6aqKkWPPQadOsGXX6q1uHWrdo/88UeIj4ekJJ4pu5BLZp7HsW3n8k73G2m2eR20aAEbNuhxrVvDcceFHuPZhLE1TcNoKFTV9GzJEpgzRwtfxsSoM6igQC1On4/HNp/NJX/cwgmp/2Nq96tpVpanBTKbNYNNmyApCdq0gY4dQ4/xbMKYpWkYDYWMDLUE/RYmqDDm56vFGBurpd7KylQ4gQdXns4/tlzNKUkf80bSxSSuKFGh7dBBX7m5anHm5weu2USrF4WKiaZhNBT69IE774TSUkhOVsFbtw5EVCjLyvRzTAw4x72+G7llyxhOS3iHic0uJb5LZ1i1Sq3LdeugfXsVyC1boFWrwH0sTrNabHpuGA2BrCx19vTpo4L5+++wejW0a6eWYhAO4faEu7iFezhbXuPVVlcQ370zxMVpaFGLFloWzufTtdC8POjcuclXLwoVszQNoyEQ7ARatUprti1dCuXluha5YQOUl+MQbi25jXu5mfObTeK55tcR23sPFcbkZK2d6Rx8+606jfbYQwVy/vxAeNLo0eYEqgazNA2jIRDsBMrNVedNs2awbZuGFbVogXNwve9+7uVmLk54gefjLiHWV6rrnAcfrKXYO3TQc4cNg/HjdxbMJhRuVFfCJpoi0lVEZojIQhFZICJXe/vHisgqEZnnvU4I1xgMo9Hgzy9fu1bXI7//Xt/z82HlSlxBIVe5R3jQXcuVLSbwVOI1xBQX6jrnkiXwySc7p0nWsTtlUyeclmYZ8A/n3F7AIcAVIrK3991Dzrm+3uvDMI7BMBoHI0YExG/bNp2Wey/fkmVcWvQwj3El18U9yqP55yPbtqolmpio0/f8fJgxY8c0ybqWlGvihG1N0zm3Bljjfc4XkYVA53DdzzAaNV7tS378URuhxcdDQQHlxWVcxPO8yPnczL3cHXcn4otRESwqCsRgJidrxk9wmuSfKCnXlKmXNU0R6Q7sD3zr7bpSRLJEZLyIpFV9pmEY2yku1vXLZs2gqIiy2ERGMYEXOZ+xcjt3y/8hZaXq6Ckv3/l8kR23rVlanQi7aIpICvAWcI1zLg94EugJ9EUt0QeqOO9iEZkjInM2bNgQ7mEaRvSQlaUW4YUX6rt/jTExUWMsi4spdXGcXfg8r/rO4h65ldvi7kaSkwLC6Jy+1q/XPPSfftI1y+DrWbO0OhFW0RSReFQwJzrnpgA459Y558qdcz7gWeCgys51zj3jnOvnnOuXnp4ezmEaRvRQnXPGOUhKonhLIacVTODN8hE8wD+4mXt1ug4qrCkpOj0vKdFzysoCa6CLFweuV8uScoYStjVNERHgeWChc+7BoP0dvfVOgOHA/HCNwTAaBMHl3r75BjZuVIFr0QJ2311jLE87DTZtomhbOaeWvsGHDOG/8neu5HFdt2zeXKfWqal6zZISFU7Q9MqkJLUmV6+G/fbT+/kbpZlI1opwBrcfDpwL/Cwi87x9twBniUhfwAHLgUvCOAbDiG6Cy73l5WmmT0yMpjXm52vz8fR0KCigoDiWYcVvMs0N4ukW13Nxl89hXZoW5+jRQx1FK1bAwoUqot27ayB8YqLeq7hYhdWcPX+KcHrPvwCkkq8sxMgw/ASH/bz7rk6zRdTzDWolbtjA1tROnFw8gVnuSMbHXsQFie9CboKmP7Zpo1WLsrPh+OPVkfPVV7pdWqoWZny8Xstfh9OcPXXG0igNI5IEh/3k5wcqDvmn17Gx5BUlcELu63ztO5CX5TzOKX8FcmLVmuzfX1Mh/aFEWVlaJi4hQS3LmBgVycRELdDRqZOuk44eHbGf3NAx0TSMSBJc7q1FCygsVDEsKYGyMraUpTBE3mVO2V94PX4Up/negBjPaiwt1Sl9sLd7yhTo2VOFeM4cdfB4DiT22SeQa27rmHXGRNMwIsmIEbqmCdCvH0ybptbhbruxOS+O45Y+RZbrw2Q5nWG+qSqWcXHqKEpK0nXMYAH0W64xMXDSSbrP51PxHD++/n9fI8QKdhhGJAkO+0lN1ZYTPXuyYUs8x6x+hfnsw9utL2JY3PsBb3jLlupVz8zUKXgwFrAedszSNIxIUyHsZ+1aGDgQlpaWMnXosxzXoRm801qn2bGxgULDnTvvLIbBlmtw8zVbw9xlmKVpGFHEqlXq21m+HD4c9BDHZa7Vcm5HHqkHlJbq1LxzZ1iwQDtNBmf5WMB62DFL0zDqi6wsePJJrTa0ZYtOxwcMgEGDYP58sn/ZyoDPbmFdcUs++SSWIz4rgJxcFb599tHQoh9/VOtx1Srd16vXzh0kLWA9rJhoGkZ9kJUFt96qBX/z8tSZs3mztrB4/32W/WUkA2bfRk5BItMG3MUhqcN3nmonJsKeewZKvlVs5evP8jHCik3PDaM+mDJFi2eUlKjXOzlZhS8/n98Ku3DUJ7eQW5TE5+e9zCF7bA4IYGVT7ZKSylv5WpZPvWCWpmHsSoLzyIPbR2Rnq6e7vDyQ1hgXx6KS3RhQ8A6lEs+Mi15kvw7rwBckgJVNtStr5Wse8nrDLE3D2FX488h/+02rrE+aBOeeC5Mnq6AlJqr3u6wMgPmFPelfOg0fMczc/1oVTKhZAP0l3X77TddHJ02CmTO1U6URdszSNIxdxZQpaknOn68B5du2qbiddx7stZeuZQIUFTGvcE8GbXmTBClleqtT6V2UB+/MU2FNStLjL7yw8mZnmZkwdGigB3p6unrTp07VjB9b1wwrZmkaxq4iO1vXHn0+Xb8sKFARLSvT73r1gubNmZN4OAO2vEWz2GJmH3c3vfeJVecO6Dm//64CW12zs/nztbvk6afDMceoWFp/n3rBRNMwdhUZGTplXrxYa2Ju3KgiCGoRFhTwdd/LGLh5Ei07Nmf2FZPoteZ/utZ5wAHaVrdNG7UcV6+uvtlZcEtfP+YMqhdsem4YoVCVgyf4+y+/1HQe53Y8t7wcSkr439LOnPD15XSI38T0Q+6nq/8457SU22GHBQoJB6dCViaG5gyKGGZpGkZN1NQf3P/9L79opaKK+HxMjz2WISufpXPzLcza9+907eJU8Fq10rTIpCQtHtyypU7Ng63IysTQ+vtEjJBEU0S6icgg73OyiFTyN8MwGik19Qf3f19UFAhCD+r8+AmDOTH/NXrErWDWwDvp1L48IIq9e+t5zmmWUOfOKpqdOlUvhpYuGTFqnJ6LyN+Ai4HWaBfJLsBTwMDwDs0wooSa+oP7v/fXw0xK2l7v8n13IqeWvc5eCUuY9pebSR9zp4qsf2rdoQMceqimR4po9aLhw9XR418KGD26cjG0dMmIEMqa5hVox8hvAZxzv4lIu7COyjCiiarWDxMTtVjGjz/C99+r6G3ZotZoeTlvM5wzyl5mv9TlfDLkv7S+9c6AyFWWHhlsKY4cWZ+/0KgFoUzPi51zJf4NEYlDm6IZRtOgsvXDpUu1iVlOjoYS/fGHCmbHjhAbyxtlp3Ja6UT+EpfFZ/teS+vTBgYE0abWDZpQLM1ZInILkCwixwKXA++Fd1iGEWU0a6adIUXgkEN07dFfNOOnn6BdO43NXLeOVxJHc557hMOazePD3a+lxa+L4G9fwRtvwJgxVomogROKaN4EjAZ+Rtvtfgg8F85BGUbUENxid+jQQFHfFSvU6szLC6xtpqQwftsZXJT7AEfHfsF77lSar3Ta5CwmRlMeCwvhnntMMBswNYqmc84HPOu9DKNpEew5B33fsEHDizp21DXJkhIoLeWpkgu5bOt/OC5hBm/Hnkaz8nxIbKvtc53TQPcNG6yEWwMnFO/5MipZw3TO7RaWERlGNFGZ5/zXXzWLJztbS7zFxPBo2eVcXfwfTkz9H5ObjyZpU74KZZz3T6ysTKf4/vOMBkso0/N+QZ+TgNPQ8CPDaPxU9JyvXau54SkpGi60di3jCi7nn+X3Mjz+fV7vfjsJ8a2hYLOmTnoVjSgrg9atdR3UsnYaNKFMzzdV2PWwiHwB/Cs8QzKMeqKm1EjYuXr6jz/qdLt1a2jRgrs3X8b/lV3E6Qnv8MrutxPfKlWn4KmpKppbt2of8/R0Fc70dMvaaeCEMj0/IGgzBrU8LSPIaNgEO3iCUyMrhv74w4P84lpSAvvvj/thLmMXncUdZRfx14RJvND8SuJKWsGGYhXGvn3VSdSsmRbxcA6OOAIuv9zWMxs4oUzPHwj6XAYsB04Py2gMo76ozMHj3+9/D7ZAR4zQfV9+ifvue24uHMO/y/7BBbEv8SyXElseDwceqBk9fvzT+kmT6ve3GWEllOn5MfUxEMOoVyo6eNatU4/4smXw9ttaBb1nTxW+W27R+MzddsM1T+Ef2y7nofKruTR5Ao+3upWYkmY69V65ckfRtFJtjZIqRVNErqvuROfcg7t+OIZRTwQ7eNat09JsIhpPKaK536mp0L69rlECvs5duWrRFTxefiFX8SgPF12LFLTQ0KOcnO3HbcdKtTVKqkujbFHDq1pEpKuIzBCRhSKyQESu9va3FpFpIvKb955W07UMY5cTnBr5yy8qlM6pd7tly0CptrVr4Y8/8C1YyCUTDuPxwgu5Xh7g4ZjrkBjRwPUNG7RYR3y8lWprAoirWDB1V11YpCPQ0Tk31ysl9wMwDDgf2Oycu09EbgLSnHM3Vnetfv36uTlz5oRlnEYTxu89nzhRS7G1a6eFN7ZtU4+3J6Ll2asYXfwEEziPW7mbO2PHIs6nVmlyslY0Sk/XTJ/g6kSVeeONqEJEfnDO9av5yACheM+T0DTKfdA4TQCccxdWd55zbg2wxvucLyILgc7AKcDR3mETgJlAtaJpGGEhOP978WJYsEAtxoICFc78fMpiEhhV8hyvcRZ3xNzGGN8dUE6gZmZxsYYfFRaqYJpQNnpCqXL0MtABGAzMQutp5tfmJiLSHdgfLS/X3hNUv7BamTkjsowYoYIp3nQbYOtWSkscZxWO5zV3FvfKLYzhrsA5aWla3ahVK1333G23qpugGY2KUESzl3NuDLDNOTcBOBHYN9QbiEgK8BZwjXMurxbnXSwic0RkzoaKC+yGsSvJzIQePXSavWwZxMdT3Hs/RspkJjOSB+Nv4KZmj+54zvr1mhmUmKjT+L33rroJmtGoCEU0S733LSLSB2gJdA/l4iISjwrmROec/2/SOm+907/uub6yc51zzzjn+jnn+qWnp4dyO8OoO337ap747rtT2L47wxfdy1TfyTzGFVzrqyRQJC4ukPGzxx5qbYKFGTUBQhHNZzwP9xhgKvAL8O+aThIRAZ4HFlYIT5oKnOd9Pg94t1YjNoxwMGIEbNpEQV4ZQ+ffw8dF/Xkm5lKuiHtGu0kWFKhFGROjXvJ991Wh9HvP/ViYUaMnlIygF5xz5eh6Zm0qGx0OnAv8LCLzvH23APcBk0RkNJCNFgAxjMiSmcnWo0/ipJdP53+lB/NCm39yXsJUKE5VJ09pqYYSJSbqOqa/YMeyZTpV9/kCtTZHj470rzHCSCiiuUxEPgbeAKa7EGOUnHNfAFLF19aUzYgq8vLghB/u5puSRF7ebSxnd5kDm9tols9uu8HGjWpplpdreBLoFL1zZ2jjHVddEzSj0RCKaO4JnIw2WBsvIu8Br3uiaBgNhyqqGuXkwJAhMHd+c14/9hlG5n4KeSUqhnvtpf1/ysrUmiwt1Sl6QQHk52uqpVVib1LUuKbpnCt0zk1yzo0A+gKp6FTdMKKLrCztDnnhhfoeHPrjr2qUk7NDVaNNsxcwcKBWfJs8GUaOO0SD3BMStFHaH3/o9qRJesCQISqcJSXQv78JZhMkFEcQItJfRJ4A5qIB7lblyIguqhDF7cIZXNUoJgbS0lif2JVjTmvLL7/Au+/CKad416q4AuXfzsyEJ5+ECRNg2DAVzilTLC6ziRFqu4t5wCTgn865beEelGHUmupKvWVmBqoarV0LixaxZmM8A5c9y/LiVrz/xFIGffsSvJmtrXk7dYJ+QZl1OTmB64Rah9NotISyprlfbYLSDSMs1FRlvbJePsExkxkZ21MlV8V0ZcDSJ1hV3JaPOl5I//fy1NnTpQt88w1s9lpVbNigHvHU1B1FuDpxNho9oaxpmmAakaWmqTeoKObm7nhecMyklyr5R2knjlr0NGuK2/BJj8von5alIUP+aXu7dppPPnu2hhqlpup1li3T+2VnqxgHYwHtTYqQ1jQNI6JUsh65U7picKm3ykqzZWaytN0hHLX0BTaVpDJtv+s5/NhmmjpZXBy4zl576XmlpVoerqhI1zT79NH71STORqPHRNOIfkKx7vy9fNLSNGYyLW2HdcbffoOjvv0PW6UF04c9ysGpC3UqvmFDoGMkaJZPSopamHl5WvrtsMM0tCg7u2ZxNho9VrndiH4SEuCTT9Rb3bIl9O5deSvc4FJvfrKyWPj0bAa88FfKXCwz9rqCzF++VQtz82YVxvx8+O47df7k5mp5uH320ZxyPzk5er+KjdYsoL3JUZ0jyF+dfU/gQDRnHDTQfXY4B2UY28nKglWrVNz8tS5nzQoElddw7s+3vs7Az28mJgZmDnuMfb77Si3EdevUitxzTy268cMPKs59+8KYMTB1qgply5Y7p0dWJs5Gk6FK0XTO3Q4gIp8CBzjn8r3tscCb9TI6w5gyJeDZ/v57nXqXl2tl9arwPO0/vraIY5c+RWJcKdP3vpo9F8xX8fOqGZGcrMenpKjl2bevBsWDWplmTRqVEErIUQZQErRdQoil4QzjT+MPJVq/Xp0z3brp1HzjRrj1Vs39LikJhCEBjBvHd8X7MXjJM6TGbGV6/In0LCjVtEh/VSJ//jiosyc9fec1UhNJoxJCEc2Xge9E5G3AAcOBl8I6KsPw4+8auWiRerOTkzUUqFkzLQK8fj0MHhwIQ2renK/W7saQ6ZfSlo3MiD+ebvHrYGsLaNtWHUQ5OWqx9u6tgllUpNN984AbIRBKnObdwAVADrAFuMA5V8NikmHsIvze6vXr1cIsLFSRA13jLCnZIQxp9vt5HPf5DXSI28TsvS6lW9mSQHGNwkKdhh92mJ63YYMK8T776JTdPOBGCIQactQMyHPOPQKsFJEeYRyTYQTwe6vbtdMpeXm5FgFetkwdRLGx2w/9fPP+DFn5LF1lJbNanESX/IUqrP4GaP5zV69Wy7J/f33fYw9LgzRCJpTc89uAfqgX/QUgHngFLTJsGOEnMxOuvBJuuUUDLlNS1LrMz1er87XX+DjxFIYvOIteMb/zWepI2sfnQqloDGZsrHrB/VZpXJwK5bZtJpZGrQnF0hwODAW2ATjnVhMIRzKM8JOVpSFAiYkqmCUl6hQqK4OYGN7bfDinzL+L3vIrM7pdQPvOni2Qm6vHxsVpmFFZmVZdP+wwFU1rgmbUgVAcQSXOOSciDkBEqon1MIww4E+jjIvTtrkianEmJDDFDeeMjY+xf4vf+aT1eaSlxUB+cSAQ3jld04yNhSOPhI4dA9e1nHGjDoRiaU4SkaeBViLyN+Az4LnwDsswgvCnUbZsGXAClZfzeslwTt/4OAem/sq0y98hrVtqoMhGYqKuYYqo0HbqBPPm7Xhdyxk36kCNlqZzbpyIHAvkoeua/3LOTQv7yAzDjz/sqHdv+PprAF4qOp0Lch/iiOY/8v6pL9MiKU1jNrdsUcuyZ091/hQVaXqkc/D551Vn+RhGiNRoaYrIv51z05xz/3TOXe+cmyYiNbbwNYxdRp8+MHOmlmuLi+P5lYM5P/dhjk7+jg9PeJwWXVoGMn3GjAl42pOT4dBDtWtkUhIMGlRlQQ/DCJVQ1jSPBW6ssO/4SvYZxq5n8mS4807NPXeOJ9efyuWb7mBI37VMeTqF5A+77ZjqCFrebeVKnao7F6hEZCJp7AKqq3J0GXA50FNEgpugtAC+CvfADIOsLBVMEcjI4JHlp3DNpus4ufMPvHnihyQeNAaSXCBH/MknYcECnZbHxqpwrl4NJ55ogmnsMqqzNF8FPgLuBW4K2p/vnNsc1lEZBqgIrl4NsbHc/8cZ3LjlOkakzeC1HneRsLrbzv163n5bxbNrV52SFxWphSpigmnsMqqrcpQL5IrII8DmoCpHLUTkYOfct/U1SKMJ4e8FNG+ermHGxnJnwT/4V/4/OTPxbV7qfh/xm/Jh4JEqqr/+qs6f4mJYs0bXNTdt0jzz5GSdnn/zTaR/ldGICCXk6Elga9D2Nm+fYexagnsB5eTg4hMYk38D/8r/J+cmT+aV1lcRv2q5pkL26QPTpmktzC1bdP2yrEzDjHJydL+fii15DeNPEIojSJwL/K1zzvlEJJTzDEOpqZOk//t33lHRS0zE/bqYm4rGcn/ZdYyOfZGnU28ltrREhXHMGJg/X0u9rVyp1mV8vHrIi4sDpeNiYzXVsn//iP10o/ERiqW5VESuEpF473U1sDTcAzMaCZMnw7nnwqRJsGSJttEN7iQZbF0WFsLq1bjFv3Ft4T3cX3Ydl/Ekz/guIjZ3s8ZXnnEGjBypAty3b8BD7pwWJhbRsnF5XhPVnj3h8ssj9vONxkcoonkpcBiwClgJHAxcHM5BGY2EYO93ero6ZhYsUGvRn/Md3GmyuBhfbDxXFI7jkfIruVoe4fGYvxMTH6s555s2aawlqMWalKRV3f1VjOLjtSL7brvp98cfry0xzAlk7EJCyQhaD5xZD2MxGhtTpmhhjfR0FTZ/e4lVqzRrZ+xYmDhRUxz33pvyhGQuWXc3z5edww38m/u4BQEtttGsmU7D589XS3PECLVQ99gjUL3I54N999VpuYUYGWGiujjNG5xz94vIf9GK7TvgnLuquguLyHjgJGC9c66Pt28s8Ddgg3fYLc65D+s4diMaycqCJ55Qj/WKFdpeIiZGvdmg1uHKleq86dZNBTM3l/Ivv+GCTeN4uehExshd3O7GIBI0EYqP1zRJf4GN4K6QBQV6vVat1NKsuGZqGLuQ6izNhd77nDpe+0XgMXZujfGQc25cHa9pRDNZWVrzcu5cFbGiIl1r3LABundX0cvNVc/2wQfrlHyvvSj96ntGrbiL17cczx3J9zKGe6DYE0wRFd2VK1UQgwtsWB8fIwJUF6f5nvc+oS4Xds7NFpHudRyX0RCZMkV7+WzcqFPlmBj1hpeXq4Xo82kl9b331spDQEl6Z87aejFTthzAv9vczw1tJ0BuS/V6+6fdiYkqvqtXW0sKI+JUNz1/j0qm5X6cc0PreM8rRWQUasH+wzmXU8X9L8ZzOGVY+a6GQXY2rF2rAhcToy9Q0SwtVdH0hwvl5FDcoi2nvXk67y3bk4eOnMI1AwqAM9XT7q+svnGjWqc+n3rY/Q4kszCNCFGd93wc8ACwDCgEnvVeW4H5dbzfk0BPoC+wxrt+pTjnnnHO9XPO9UtPT6/j7Yx6JSNDPePO6bTa59MXqHOmWTOtwN6nD4UbtnLK80N5b/GePNHhdq7JvV0D1keM0PXL3FwNIWrhNQno0AF69Ah0nfSHLBlGPVOlaDrnZjnnZgH7O+fOcM69573OBo6oy82cc+ucc+XOOR8qwAfVbdhGVDJihAqdcyqW5eUBqzMhQUu2paWxbe6vnPTzvXy6dl+e6/h/XLbHdBXMqVP1OmPGBNZC8/L0vKQkrV7kD0+yNhVGhAglTjNdRHbzb3idKOtk+olIUK8BhlN3i9WIRjIz4fzzVSTLylQ4RdTKbNsW9tqL/KR0Thg/kpkL2jLh2ImMvjgOjjlGnTx+MRw5El5+GU4/XcW2Q4dAXUywNhVGRAklHfJaYKaI+LOAugOX1HSSiLwGHA20FZGVwG3A0SLSF10rXR7KdYwGRFaWWofHHgs//qifndMKRIMHk9syg+MnnMl367sx8ahnOPOQ1ezw/3awGAZ7xnNyVFD9WJsKI4KEEtz+sYjsDvT2di1yzhWHcN5Zlex+vpbjMxoS/uye3XaDgw5Sp9CsWZCaSk5KVwa/eDY/ru/MG+OyOTVvLeTk1iyG/iB2sDYVRlQQSruLZsA/gSudcz8BGSJyUthHZjQ8/A3QgmnWjI2/bmLAYyP4aUMnpjy8glOv665i6K+o7veM5+TsHFLkD2K3NhVGlBDK9PwF4AfgUG97JfAm8H64BmU0ECpWL0pICPQa//57WLqU9bEdGVT8EYtLuvFut6sYMn0NbO6r4ujP6AluV1GZGFoQuxFFhCKaPZ1zZ4jIWQDOuUIRkTCPy4h2KlZNz8nRnPLcXE2f3LiRNSVtGFg6meWuCx90/hsDU3+CnJaBsKHrr9f88+Brjh1bdQk5w4gCQhHNEhFJxgt0F5GeQI1rmkYjZ8oUDSn68ktYvlxTJuPitgeyryxpxwA3jdV05KPYE+m/8SuIba+l3PzrmFOmBESxMhH2C6sJpxFFhCKatwEfA11FZCJwOHB+OAdlRBmVFRGeN0/LvG3YoGXZYmJUEEtKWE43BjCdTbThUwZzmO9r8MWpsBYVqYOoXbsdw4aCS8RB5cJqGFFAtaIpWmYmDRgBHAIIcLVzbmM9jM2IBqqyAFeu1MDz8nK1MGNjoaiIJezGAKaTRyqfMYgDmaNzFH/MZtu2mp+emLijpzw7W68fjMVjGlFItd5zL3PnSufcJufcB865900wmxjBFmBMTOBzXp46fMrLt6dM/urrRX9msZUUpjNQBdNPfLwKZuvWsH79zp7yjAxdDw3G4jGNKCSUjKBpInK9iHQVkdb+V9hHZkQHFcOI1q3TqfmmTWphApSV8Yvbi/7MooQEZnI0+/Ojiimo2J50kormxo06Na+4VhlqCJJhRJhQ1jQv9N6vCNrngN0qOdZobGRkBDJy1q2Dr75SMezeHTZvhsJCsshk0LZ3iaWMmRzN3jG/QkxcoFhHaqrmjXfqpNeqzLkTXFS4phAkw4ggoWQE9aiPgRhRSnBGzi+/qGA6BwceCCLMnbaJY5c+RTKFTE8Ywh7ud4j1qrX7qx0NGqRroDUJocVjGg2AGkVTRJKAy9HKRg74H/CUc64ozGMzooFgC3D1arUW99oLOnTgu1WdGbzqr6Q228aM4x9lt72Gw8KF8MUXWrndX6hjzBgTQ6PREMr0/CUgH/ivt30W8DJwWrgGZUQJFUONBg1SB9CiRXz5YS7Hr/wH6bHrmb7fDXRr2xpyE7QXebt2erzf0rR4S6MREYpo7umc2y9oe4aI/BSuARkRxC+S8+bpdHrdOrUs+/bVtcj582HZMmbKMZy08ik6x6zm85ghdMkuhM0pWrqtuFjDiUA/H3aYpldavKXRSAhFNH8UkUOcc98AiMjBwJfhHZZR7/jjMcvKNGh9zRptUVFcrILZty8sXcpnm/dnaNHT9GAZn8UcT8ekXEjwAtH9Pc2TkqBrVxXM9u3VIWTxlkYjIRTRPBgYJSL+v/UZwEIR+RlwzjkzHxo6WVlw4YXwxx/al8fn06l1fPz2LB8+/5yPth3F8OLX2IPFfMaxtJMcKI3T9Ut/87O0NG2lW1oauL7FWxqNiFBEc0jYR2FEDn/b3d9+g5QUtSr9a5Gxsds7Sk7dNpDTyl5lHxYwLf5E2pSuhzKvvW5RkYpmixYB8RRRb3tCgtW/NBoVoYQc/VEfAzEixJQpmj+ekqLb/lAhUGsxOZnJRSdxVtkEDpAf+TjhFNJi81QwndOMINDPqanqCOrdW73oq1drKwuLtzQaEaFYmkZjJjtb1y07dFDnT3y8bpeXQ0wMrxYOZ1TZ8xzMt3wUP4zUmG0QE6vH+afgzZoF0iz32kvXMRMTVTCDS78ZRiPARLMpUVm1oowMdeCAOm9Wr9bccBEmyPlcUPYsRzGb9zmJlJJtOmWPjdWuk6mpuua5996aHdSnD6SnB1IgbUpuNEJMNJsK/rVLfym3BQtgzhztHjlnDixZomuSXbpAQQHPloziksKHGRgzg3djRtAsphRKJdCWt6xMc9LHjdPukRUF2abkRiPFRLMxUplF+cQTKoypqSp2RUW6/dlncM89+v0334AIjydex5W5/+L41t8wpWAkSXE+iEkKWJnl5Tolf/nlgDBaCqTRRBDnX/SPYvr16+fmzJlT84HGjvUvW7aE339Xq3L5cnX2dOwYcPoUFGg40bx5209/6CG47joY2uNnJrUYTeISL99cPE95y5YaltS1q7bpNYwGjIj84JzrV5tzQikNZzQkgutfrl+vginetLqsTPv3bN0aOD6o3dN996lgnrrbXN6U00ncuErLv5WWBoLWi71OJ4ccUs8/zDCiA5ueNzays9WzPXOmVkiPjVXPeFJSoMr6hg26Pz8f9t0Xxo7ljqn7cduPwzmr0yxeOuEd4kqO0jJwW7boOcnJKpwA++wDl10WyV9pGBHDRLOhU3H9Mj9fc8RTU/V75zTTp107Fb1t27ToRocO0K4dblsBYz48lLt/HMyoNh8wvsUNxJYdpdP4U0/VoPdff9VzRdTCvOwyW780miwmmg2Zyvr3/PSTTqdTU1XkcnPVwkxI0JAg/3Q9ORnXNp0bll3KuLkDuajD+zxdfD4xeQnas/ykk/QePXtqzOX48ZH9rYYRJZhoNmQq6+AYF6ehQ+XlgT4+MTHanuKrrzSO8qSTcIlJXPPS/jyaO5DL27zOf7s+TMz6FI27XLpUKxy1b29544ZRAXMENWQq9u8BFcXCQv2cnKzFMxIStAhHWRkkJ+MjhssmD+TR3PO5Nv4xHutwNzHNkrRgcHm5ron+8ov16TGMSjBLsyET3L/HT5cu6rz54w8VS3+oUEICJCZSvm4jf3t9IC/kDeWmpIe4p/h6ZEUKJCaoldq6tVqqljduGJUSNktTRMaLyHoRmR+0r7WITBOR37z3tOquYdRAxQ6OixerE6h1a7U2CwrUauzaFVq0oKwMzt/yMC/kjeRfKQ9yT9o4JClRw4j++EMt04ED4Ygj4JxzNG/cBNMwdiCc0/MX2bms3E3A58653YHPvW2jrvj796SlqVNowQJ19hx5JPTooZ7zlBRo3pzSlDTOyXmMV3xnc1fKfdye+gBSXKSZPc6pwO65Z6CUm03JDaNSwiaazrnZwOYKu08BJnifJwDDwnX/JkNmplqEffvC0Uer13z2bPWgi8D69ZTkbOOM1Q8yqWwE/2l2G7cmPRAo/5aYGAhP+vxzdRxZPx/DqJL6XtNs75xbA+CcWyMi7er5/o0Xf1D7jBkai+k5dIqKYOT6J/kg50AeuWAeV2V9AL+V7NjLxzmtVHT44Wq1mmAaRpVErSNIRC4GLgbIsJCXyotwBItbRga89ZamTpaUQFkZheUJDHNv82n+gTyZcS+XTr5XM4HKyrRgR0GBWplt20K/fuqJt14+hlEt9S2a60Sko2dldgTWV3Wgc+4Z4BnQgh31NcCopLIg9ltvhc6dVSAzMnQt86GH1AHk87HNNeNk3zvM5Gie50IuXP2yeseLi9WyTEjQ9+Ji2G8/zRDKybGYTMOogfoWzanAecB93vu79Xz/hknFIPaSEvWSz52rcZn+2pgAzpHvUjjRN5UvOZyXGMVfmQhe2vj2tUyfT6fnsbFqnXbqZIWDDSMEwhly9BrwNbCniKwUkdGoWB4rIr8Bx3rbRk1UDGL//vtAto9//5IlAGyhFcf5PuIrDuNVzlbBhEClI59P30VUNMvLYdkyFWRzABlGjYTN0nTOnVXFVwPDdc9Gh38dc+5ctSYPOEBTG1euDFQe8vLIcY7NLo3BZZP5iUze5DSG807gWl5Xye2l4ER0it62rVqZ1svHMELC0iijFf86Zk4OHHywWpYzZ8KaNSp+5eUqeB4bS1sysGAqWezLFEbsKJiwY9dI0Kyftm21ZFyrVvXxiwyjURC13vMmT8V1zP79tVL6d99Bt25agCM2FpxjXX4zBv7yKEt8XZmacg6DCz4CXyXX9FuXHTuqULZsqc6k3Xevz19mGA0aszSjlYrrmB06wODBsP/+WqatTx8AVm9M4OiFT7CsvCsfnPQUg5NmqTAmJemU3I+IWpcHHghDh8LJJ6vXPDbWsn8MoxaYaEYrGRlali0Yf5m2zEy4+25WHHYG/Ve8wkpfJz5+biUD7hqglqm/W2RMjK59JibqVLx3bxXbtDRdFzXnj2HUGpueRxt+58+8eerV7tNHCwH7G6T16AFjx7L84DM45p3r2Czw6Uw49NBeev4996gQrlih24mJanm2aqWplsXF5vQxjD+BiWY0ERzE3r69CuWHH+pU2x9elJPD73PzGPCfduTHlvH59Dj6BffSGzkS9tgDLrxQKxfFxmpA/IEHBtYzDcOoMyaa0YTf+VNSoj3ImzeHNm1U/LyamIvWtGTgVzdRHJvAjHOfo2+/S3e+TmamrnsGt/LNzbXgdcPYBdiaZjThd/4sXKhB6CtW6BS9vBxiYpif25WjlzxHmYtlZp+/07fku6qvFVw2ztYvDWOXYZZmNOGvxL52rb4XFGwPRv+pZC8G+T4gPqac6e3OpHfBWsg4vfrrZWaaSBrGLsYszWjCX4k9P1+3PQvzh5gDOcb3GUkUMSttOL03f6XCunatroMahlFvmGhGE/4pdYsWWkQ4NpZvEo5iYNnHpJLH7PhB7J4/V49t316LDZ97LkyeHNlxG0YTwkQzmvCHGyUnQ+fOfNHmFI7d9jZtY3KYnTaMHnEr9Lt27bQOZnq6Tt/vvNMsTsOoJ0w0o4XgXPODDmJG7gEMzn6Gzil5zNr9IjLwKrMnJ2vo0Lp18Ouvgen8lCmR/gWG0SQw0YwWpkzRNcyffuLTz2I4YeXTdE9Yzcz00+icuBGOP16D07dtU294QYEGrhcV6b558yL9CwyjSWDe82hh3jxYupQPiwcyYtl97JmUzWfdLyLdtxmOHqwhQy1awA8/6PHFxWp5iuhUfcuWSI7eMJoMJpqRJLjvz7x5vFN6AqevuZ99my/l08x/0mZbLqzdEijc0aGD5pCvX6+i6a+CFBNj5d0Mo54w0YwU/jXMDRtg4ULeXHEIZ/se4S8JP/Nx5hhalW3UAPdWrTSbx18irnt3nZb7RdPKuxlGvWKiGS5q6h45ZYoK5jffMNF3FqN8/+Uw+ZoPyk4mdaXnGff59DVzZqBwR+fOes3DDoNevQLpkVbezTDqBXMEhYNgT7i/e+S4cTuGBWVnw8KFvFh+LufmPcZRCd/wUdIIUuMKNPfc37v8mGNgn320kVpWllqU99+vRTksPdIw6h2zNMNBxarr/vcnn9Sg9OxsWLqUZ9YO5ZLiRzk2YRbvJJ1Js+I8rYW5aZNap/vvr+uYHTuq5ZmWFijrNnJkRH6aYTR1TDTDQXa2Wpig8ZQLF2pvnw0bYMgQ6NWLx7KO4u/F53NC7Ce8FXsWSeUlWsYtKUnDiPr2VcH007KlXtcwjIhiorkrqdg9sls3DUBPSoKtWzUofcECHlg2gut/GMkprWfzxpbhJJaXQ1yihhD5fLpuOW/ejrUv/VXbDcOIKLamuauo2D1y/Xp4/31YvlzXHrduhbQ07l12Jtd/M5LT0mfwZv/HSUxExbK0VL3igwbpa9MmvZbPp+/m7DGMqMAszV1F8DrmunUqhM5tb53rHNyx5K+MLb2Zs2NeZ4K7lrhP8iAlRcOIRHRa3ratWqTHHqvX8nvfR482Z49hRAEmmruK4HXMhQtV8PLzITcXV1bOrdtu4V7fjZwf+xLPNbua2IIStS6bN9eYy6QktTTnzoU99zSPuGFEKTY931UEd49cu1ZFdONGXGER12+8kXt9N3IxT/N83KXExseoZdmyJRQWwqGHaiGOkhIVUBNMw4hazNLcVYwYoWuaGzfqemZuLj6f42oe5THflVzJf3mUq5AWbTXucvlyFUxQL3mHDrpumZZmgmkYUYxZmruKzEwYOhRmzID8fHw+x2U8yWNcyT/kQR6Va5D4eA1ad06LbxQWBjJ/zNljGA0CE81dRVYWTJ0KpaWUt23PaBnPM1zCzXIf/4m9CYmPg2bN9Fj/NL51a52ST51q03LDaCDY9Lwyasobr+y4pUuhUyfKYhI4L/dRXnUjGCu386/Yu5GkRPWip6VpS94uXbTLZMX8ccMwop6IWJoislxEfhaReSIyJxJjqJJQ8sYrO279ekp/XsTZhc/zauEI7ml+F7cl3Is4X8BLvs8+2o+8b184+mjNH4+JCYQqWfV1w4h6Ijk9P8Y519c51y+CY9iZ4HjL6gStwnHFbTtzWvYDvJk/hAfa3svNLZ/UMKLkZF23PPVUuOcetVj9/c2DsTRJw2gQ2PS8IsHxln4qE7Sg44rK4jj1jwf5MG9f/tv+Lq48ZQXM66JZPYMGweWX7zi99/c39xfyAEuTNIwGQqRE0wGfiogDnnbOPROhcexMRgYsXgyrV6uQtWwJnTrpVBp2yi8v2Pdghs24mmnZPXn6oOe4OPkzKN1Ne/pUtRbqD08Cvb5/TXP06Pr7nYZh1IlIiebhzrnVItIOmCYii5xzs4MPEJGLgYsBMsJlgVXm8OnTB156Sfvu+HvvZGfDX/4Cl10G06apM6dXL7b+vIyTXzuHWQU9GD/oVS5Iehc691aPeHX4+5sH39vSJA2jQSDOucgOQGQssNU5N66qY/r16+fmzNnF/iK/I8ffMsJv7TVvDnl5sGpVwNJs3lyLbiQlaYylCHnbYjlh7Xi+3rQ7L2WM4ZwTcmDFCq2uHnw9CyMyjKhFRH6orV+l3i1NEWkOxDjn8r3PxwF31Pc4qiwUPHs2nHzyjj13ZsxQD3hMDKSmsqW8BUOW38cPBb14/dTJnJa6FtpnaKGNitebMsVE0zAaEZGYnrcH3hYR//1fdc59XO+jqMrh49yOjcxAiwenp4MIm/PjOW7xA2QV7Mab3f7JsM4+SMsI3YFkGEaDpt5F0zm3FNivvu+7E1V5sHffXRuZlZaqUHbpomXeOndmQ0JnBr1xEb8Wd+ftXjdwYtpXkLOnrkdOmWIeccNoAjTdNMoRIwL53v7c7yVLtKblPvuoYG7YoA3NRo1ibWkbjn7vOhaX9mDqHv/kRN972sPHv2ZZ2fUsl9wwGh1NN06zMg921666LllSoiFHiYmQkMCqeRsY8P04VuYLHx77MMcc3BpGVFirNI+4YTQJIu49D4WweM8r48ILdSr+zTfqKU9KIntLKgN+eYx1CV346JNYjjgi/MMwDKN+aBDe86gmIwM++mh7+uOywg4MWPQgOa4F0856gUNSD4KxIRTyMAyj0dJ01zQrY8QITX10jt82tOKoOQ+SW5rM57tfyiFLJoZWyMMwjEaNiWYwmZkwaBALczrQf+GTFJHIjD0v4y+JC+CXXwLl3awykWE0WUw0KzD/2Gs5evkL+GLjmbn/deyXukxjN/1ZQcFYHKZhNDlsTTMo/3xewkEMeuMiEuNymd7nGvYsWwApLTW0aOFCDUEKxuIwDaPJ0bQtzaBCwnNiDmLAi+fSrCSXWcMeZs/dfYEc8kWLtFVFfLzFYRpGE6fpWppZWRpi9McffF1+EENy76Z180JmnPo43bf9CnPm7Fzp6IortJe5xWEaRpOlaYpmVhbccgv89huz4wdy4paX6CDrmd7mfLom7AXzftNe5P5KR61aaZZQfj6MHRvp0RuGEUGapmhOmQIbNjBdBnLyppfJkJV8nnQSnbblwrxidfz07LljpSOfz5w+hmE00TXN7Gw+WdWHE3Mn0kOWMzP5eDrFrNVp+OrVcMghgTa7fszpYxgGTVQ03y8axNBVT7Bn3BJmpJ9B+/jNGoMZHw/t22tPHyu+YRhGJTQ50Xz7bRjx5plkxi9ieothpMflqGe8WTPo3FmzffzFN9LSNDYzLc0qsBuGATSxNc033oBzzoEDD4zh494v0PL7JNi4Vb/s3l2bp/kbqGVmmkgahrETTUY0X3kFzjsPDjsMPvwQWiy7EMZt3rlHkE3BDcOohiYxPR8/HkaNgv794eOPoUULbApuGEadaPSW5lNPaefd447T9cxmzYK+tCm4YRi1pFFbmo8+qoJ54onw7rsVBNMwDKMONFrRHDcOrr4ahg/XWPakpEiPyDCMxkCjFM2774Z//hNOP1095gkJkR6RYRiNhUYlms7BbbfB//0f/PWvMHGixqsbhmHsKhqNI8g5uPlm+Pe/4YIL4NlnITY20qMyDKOx0SgsTefgH/9Qwbz0UnjuORNMwzDCQ4MXTZ8P/v53eOghuOoqeOIJbeFjGIYRDhr09Nzng0suUcvy+uvh/vtBJNKjMgyjMdNgbbLyci28/txzcOutJpiGYdQPDdLSLCvTtMjXXoM77oAxYyI9IsMwmgoRsTRFZIiI/Coiv4vITbU5t7QUzjxTBfO++0wwDcOoX+pdNEUkFngcOB7YGzhLRPYO5dziYhg5Et56Cx58EG68MZwjNQzD2JlIWJoHAb8755Y650qA14FTajqpsFBTIqdOhcceg2uvDfs4DcMwdiISotkZWBG0vdLbVyU+HwwdqmXdnnlGO+kahmFEgkg4girzcbudDhK5GLgYIDExk9JSeOEFLSRsGIYRKSJhaa4EugZtdwFWVzzIOfeMc66fc65fcXE8L79sgmkYRuQR53Yy8sJ7Q5E4YDEwEFgFfA+c7ZxbUM05G4A/gLbAxvoYZx2I5rFBdI8vmscGNr4/QzSPDWBP51yL2pxQ79Nz51yZiFwJfALEAuOrE0zvnHQAEZnjnOtXD8OsNdE8Noju8UXz2MDG92eI5rGBjq+250QkuN059yHwYSTubRiG8WdosGmUhmEYkaChieYzkR5ANUTz2CC6xxfNYwMb358hmscGdRhfvTuCDMMwGjINzdI0DMOIKA1CNP9MgY/6QESWi8jPIjKvLt64MIxnvIisF5H5Qftai8g0EfnNe0+LorGNFZFV3vObJyInRGhsXUVkhogsFJEFInK1tz9anl1V44uW55ckIt+JyE/e+G739kf8+VUztlo/u6ifnnsFPhYDx6KB8d8DZznnfonowIIQkeVAP+dcVMSjichRwFbgJedcH2/f/cBm59x93n88ac65ei95UsXYxgJbnXPj6ns8FcbWEejonJsrIi2AH4BhwPlEx7OranynEx3PT4DmzrmtIhIPfAFcDYwgws+vmrENoZbPriFYmnUq8NGUcc7NBjZX2H0KMMH7PAH9x1bvVDG2qMA5t8Y5N9f7nA8sROsiRMuzq2p8UYFTtnqb8d7LEQXPr5qx1ZqGIJq1LvARARzwqYj84OXMRyPtnXNrQP/xAe0iPJ6KXCkiWd70PSLT32BEpDuwP/AtUfjsKowPouT5iUisiMwD1gPTnHNR8/yqGBvU8tk1BNEMqcBHhDncOXcAWiP0Cm8KaoTOk0BPoC+wBnggkoMRkRTgLeAa51xeJMdSGZWML2qen3Ou3DnXF60pcZCI9InUWCpSxdhq/ewagmiGVOAjkjjnVnvv64G30SWFaGOdtybmXxtbH+HxbMc5t877C+0DniWCz89b73oLmOicm+LtjppnV9n4oun5+XHObQFmomuGUfP8YMex1eXZNQTR/B7YXUR6iEgCcCYwNcJj2o6INPcW5RGR5sBxwPzqz4oIUwF/najzgHcjOJYd8P+D8hhOhJ6f5yx4HljonHsw6KuoeHZVjS+Knl+6iLTyPicDg4BFRMHzq2psdXp2zrmofwEnoB70JcCtkR5PhbHtBvzkvRZEw/iA19CpRilqqY8G2gCfA795762jaGwvAz8DWeg/sI4RGtsR6NJPFjDPe50QRc+uqvFFy/PLBH70xjEf+Je3P+LPr5qx1frZRX3IkWEYRjTREKbnhmEYUYOJpmEYRi0w0TQMw6gFJpqGYRi1wETTMAyjFphoGlGLV4Hm+kr2DxORvetwve4icnbQ9vki8tifHWcl95kpIlHbF8f4c5hoGn8K0e6i9c0woFLRrGE83YGzq/neMGrERNOoEhEZIyKLvBqIr/mtPs+SukdEZgFXi8hAEflRtKboeBFJ9I5bLiJtvc/9RGSm93msd9xMEVkqIlcF3fNW0dqpnwF7VjKmw4ChwH+8+oc9KxnPiyIyMugcf3Wb+4AjvfOu9fZ1EpGPRWs93l/J/Y4XkUlB20eLyHve5ydFZI4E1Wes5PytQZ9HisiL3ud0EXlLRL73XodX/6dhRAsR6UZpRD/e9PJUtJJOHDAXrd/op5Vzrr+IJKGZHgOdc4tF5CXgMuDhGm7RGzgGaAH8KiJPolkbZ1ZzT5xzX4nIVOB959xkb6zbx+Ntv1jFPW8CrnfOneQddz5aqGF/oNgbx3+dc8FVtaYBT4tIc+fcNuAM4A3vu1udc5tFa75+LiKZzrmsGn63n0eAh5xzX4hIBtrSeq8QzzUiiFmaRlUcAbzrnCt0WrvxvQrf+4VjT2CZc26xtz0BCKXK0wfOuWKnhZvXA+2BI4G3nXMFTqv31KbGwBs1H1Ipnzvncp1zRcAvQLfgL51zZcDHwMne1P9EArnTp4vIXDQ9bx+qWDKogkHAY16psqlAqr+GgRHdmKVpVEVlJfmC2RbCcWUE/mNOqvBdcdDncgJ/F+ua17st6PP2+3pFLhKqOa+qcQTzBnAFWjz5e+dcvoj0AK4HDnTO5XjWbcXfCDv+nuDvY4BDnXOF1YzNiELM0jSq4gvUukry6jeeWMVxi4DuItLL2z4XmOV9Xg78xft8agj3nA0MF5Fkz+o6uYrj8tFpfVUE3/cUtEp3KOdVxUzgAOBvBCzaVFSoc0WkPVpLtTLWicheIhKDVtHx8ylwpX9DRPrWYVxGBDDRNCrFOfc9Om38CZgCzAFyKzmuCLgAeFNEfgZ8wFPe17cDj4jI/1ArrqZ7zkVFaR5aM/J/VRz6OvBPz/nUs5LvnwX6i8h3wMEErNAsoEy0uda1lZxX1bjKgfdRYXzf2/cTOi1fAIwHvqzi9Ju8c6aj1Z38XAX0E60Y/gtwaajjMSKLVTkyqkREUpw2omqGWoEXe8JmGE0WW9M0quMZL4g8CZhggmkYZmkahmHUClvTNAzDqAUmmoZhGLXARNMwDKMWmGgahmHUAhNNwzCMWmCiaRiGUQv+H1snZPa5bqHnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "del model\n",
    "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
    "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "model.load_state_dict(ckpt)\n",
    "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQikz3IPiyPf"
   },
   "source": [
    "# **Testing**\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8cTuQjQQOon",
    "outputId": "6bc5de07-4c5a-4e87-9ae3-d09f539c5f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to pred.csv\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
    "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfrVxqJanGpE"
   },
   "source": [
    "# **Hints**\n",
    "\n",
    "## **Simple Baseline**\n",
    "* Run sample code\n",
    "\n",
    "## **Medium Baseline**\n",
    "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
    "\n",
    "## **Strong Baseline**\n",
    "* Feature selection (what other features are useful?)\n",
    "* DNN architecture (layers? dimension? activation function?)\n",
    "* Training (mini-batch? optimizer? learning rate?)\n",
    "* L2 regularization\n",
    "* There are some mistakes in the sample code, can you find them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tmCwXgpot3t"
   },
   "source": [
    "# **Reference**\n",
    "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
    "Copying or reusing this code is required to specify the original author. \n",
    "\n",
    "E.g.  \n",
    "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML2021Spring - HW1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
